{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generation of table of powerfits\n",
    "Tim Tyree<br>\n",
    "8.30.2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:58.217901Z",
     "start_time": "2022-02-07T20:57:57.166409Z"
    }
   },
   "outputs": [],
   "source": [
    "from lib.my_initialization import *\n",
    "from lib import *\n",
    "from lib.lib_care.measure.level_sets import comp_longest_level_set_and_smooth\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import random,scipy\n",
    "from scipy.interpolate import LinearNDInterpolator\n",
    "from scipy.interpolate import CloughTocher2DInterpolator\n",
    "import matplotlib as mpl #for colorbar\n",
    "from scipy import stats\n",
    "#DONE: hook this routine up to dask\n",
    "#DONT: hook this routine up to dask_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:58.348997Z",
     "start_time": "2022-02-07T20:57:58.328496Z"
    }
   },
   "outputs": [],
   "source": [
    "darkmode=False\n",
    "if darkmode:\n",
    "    # For darkmode plots\n",
    "    from jupyterthemes import jtplot\n",
    "    jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Introductary Notes__\n",
    "- fits may be recomputed by evaluating the .ipynb associated with fitting powerlaws to the full models.\n",
    "- here, the powerlaw fit is w=M*q**m, and Delta_X is the maximum disagreement one could expect to observe with 95% confidence.\n",
    "- here, we observe Delta_X concerns disagreements between statistically independent measurements of X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:58.481563Z",
     "start_time": "2022-02-07T20:57:58.462035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fk_pbc lr_pbc fk_ncbc lr_ncbc\n"
     ]
    }
   ],
   "source": [
    "wjr=recall_powerlaw_fits_to_full_models()\n",
    "print(*wjr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:58.677267Z",
     "start_time": "2022-02-07T20:57:58.658813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9505909539362845+0j)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(1-1j/(2*np.pi))+1/(1+1j/(2*np.pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T02:35:58.550581Z",
     "start_time": "2021-09-03T02:35:58.521896Z"
    },
    "code_folding": []
   },
   "source": [
    "# gener_powerlaw_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:58:00.768169Z",
     "start_time": "2022-02-07T20:58:00.750382Z"
    }
   },
   "outputs": [],
   "source": [
    "# #generate a csv of all powerlaw fits for a folder containing .csv files returned by postprocessing the raw output data log printed in tim's custom c and perl code\n",
    "# input_fn=search_for_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:58:00.939735Z",
     "start_time": "2022-02-07T20:58:00.923474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function lib.routines.gener_powerlaw_fits.gener_df_powerlaw_fits_and_to_csv(input_fn, save_folder=None, save_fn=None, printing=True, **kwargs)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gener_df_powerlaw_fits_and_to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T21:16:34.840298Z",
     "start_time": "2022-02-07T21:16:34.808951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>CollTime</th>\n",
       "      <th>r</th>\n",
       "      <th>D</th>\n",
       "      <th>L</th>\n",
       "      <th>kappa</th>\n",
       "      <th>reflect</th>\n",
       "      <th>set_second</th>\n",
       "      <th>niter</th>\n",
       "      <th>dt</th>\n",
       "      <th>Dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005998</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7.07107</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7.07107</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7.07107</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7.07107</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7.07107</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   N  CollTime  r  D        L  kappa  reflect  set_second  niter       dt  Dt\n",
       "0  5  0.005998  2  5  7.07107    500        0           0   1500  0.00001   1\n",
       "1  6  0.001087  2  5  7.07107    500        0           0   1500  0.00001   1\n",
       "2  7  0.000460  2  5  7.07107    500        0           0   1500  0.00001   1\n",
       "3  8  0.000322  2  5  7.07107    500        0           0   1500  0.00001   1\n",
       "4  9  0.000244  2  5  7.07107    500        0           0   1500  0.00001   1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #run 5 uses a weird beta parameter\n",
    "# input_fn='/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_5_all/job.out.8923457.1'\n",
    "#run 6 looks right, but uses the ballistic method Dt/dt\n",
    "input_fn='/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_6_all/job.out.8925250.182148'\n",
    "#run 7 uses temperature_energy, energy_gap, and Dratio\n",
    "# input_fn='/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_7_all/job.out.9090167.49829'\n",
    "input_fn='/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_6_all/job.out.9589138.999'\n",
    "W\n",
    "df=pd.read_csv(input_fn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T21:45:23.122600Z",
     "start_time": "2022-02-07T21:27:02.441728Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing input_fn\n",
      "{'m': 1.8448860150681474, 'Delta_m': 0.08586079487095431, 'M': 1618.1174655487837, 'Delta_M': 864.1108055598017, 'Rsq': 0.9763297115312686, 'rmse': 143.15750156231488, 'rmse_full': 899.5873689538871, 'model_name_full': 'lr_pbc', 'q_min': 0.09999993811023832, 'q_max': 1.0, 'r': 2, 'kappa': 500, 'D': 5, 'varkappa': 0, 'x0': 0, 'L': 7.07107, 'force_code': 2, 'neighbor': 0, 'reflect': 0, 'set_second': 0, 'no_repulsion': 0, 'no_attraction': 0, 'dt': 1e-05, 'Dt': 1}\n",
      "parsing absolute directory of input_fn=/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_6_all/job.out.8925250.182148...\n",
      "We're about to use 12 cores to obliterate 181944 csv files from /home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_6_all\n",
      "run time for computing powerlaw fits was 1097.07 seconds.\n",
      "computed powerlaw fits for  181944 trials successfully.\n",
      "parsing absolute directory of input_fn=/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_6_all/job.out.8925250.182148...\n",
      "powerlaw fits from particle model were successfully saved in \n",
      "/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_6_all_powerlaw_fits.csv\n"
     ]
    }
   ],
   "source": [
    "# 'q_max':0.4,\n",
    "# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_23_all/job.out.21392526.13\"\n",
    "# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_22_all/job.out.21389603.156\"\n",
    "# 'q_max':None,\n",
    "# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_21_all/job.out.21377943.553\"\n",
    "# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_20_all/job.out.21377943.2385\"\n",
    "# input_fn=\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_19_all/job.out.19842066.24\"\n",
    "# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_18_all/job.out.16106771.17\"\n",
    "# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_17_all/job.out.15270959.1\"\n",
    "# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/local_results/black_star_run_1_all/out.0\"\n",
    "# input_fn=\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_16_all/job.out.14688026.14\"\n",
    "# input_fn=\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_15_all/job.out.13954413.14\"\n",
    "printing=True\n",
    "kwargs={\n",
    "    'q_max':1.,\n",
    "#     'q_max':0.4,\n",
    "#     'q_max':None,\n",
    "       }\n",
    "npartitions=os.cpu_count()\n",
    "save_dir=gener_df_powerlaw_fits_and_to_csv(input_fn,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T21:45:23.881714Z",
     "start_time": "2022-02-07T21:45:23.252270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0007\u0007\u0007"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## scratchwerk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "__Notes on nonsense local data__\n",
    "- I still cannot explain/reproduce the anomalous drop in reaction rates\n",
    "- This doesn't seem to be a problem with the remote data generation pipeline\n",
    "- Quickest fix is to dev run 16 to run the ~55 jobs I have right now in run_15_all_ar_star.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.039604Z",
     "start_time": "2022-02-07T20:57:16.037287Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# input_fn=search_for_file('/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.047590Z",
     "start_time": "2022-02-07T20:57:16.042889Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# input_fn='/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_18_all.csv'\n",
    "# print(input_fn)\n",
    "# df=pd.read_csv(input_fn)\n",
    "# neighbor_values=np.array(sorted(set(df.neighbor.values)))\n",
    "# neighbor_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.053159Z",
     "start_time": "2022-02-07T20:57:16.049031Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#DONE: confirmed that I do not currently have the data needed to get ar_star locations for neighbors=1\n",
    "#TODO: find the run that predicted my latest ar_star settings (run 17?)\n",
    "#TODO: dev run 19 from (17?) with neighbors=1\n",
    "#TODO: compute the ar_star settings as before.  \n",
    "#TODO: quantify any disagreements in the ar_star settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.059087Z",
     "start_time": "2022-02-07T20:57:16.054612Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 1/np.array((0.000636,0.000682,0.000777,0.000799,0.000835,0.000951,0.001034,0.001128,0.001226,0.001340,0.001527,0.001732,0.002003,0.002261,0.002559,0.003207,0.003636,0.000607,0.000682,0.000812,0.000928,0.001092,0.001458,0.001749,0.002237,0.003017,0.005223,0.008314,0.015124,0.081308))\n",
    "# print(f\"do i get these coll times for 83 and 84???\")\n",
    "# print((1/0.003636,1/0.000607))\n",
    "# \"\"\"Printing Outputs...\n",
    "# exit_code=1\n",
    "# ntips=83\n",
    "# Tcount=1497\n",
    "# Tsum=3.79943\n",
    "# Tavg=0.00253803\n",
    "# \"\"\"0.002538,\n",
    "\n",
    "# \"\"\"Printing Outputs...\n",
    "# exit_code=1\n",
    "# ntips=84\n",
    "# Tcount=1494\n",
    "# Tsum=3.70288\n",
    "# Tavg=0.0024785\n",
    "# \"\"\"0.002538,0.002478,\n",
    "\n",
    "# print(\"Nope. rerunning with the numerical value parsing line from return_CollTimes.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.064780Z",
     "start_time": "2022-02-07T20:57:16.060806Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # # export Tavg=$(./return_CollTime.x < tmp.input | grep 'Tavg=' | grep -Eo \"[-+]?[0-9]*\\.?[0-9]+([eE][-+]?[0-9]+)?.\"); printf \"%f,\" $Tavg\n",
    "# # !echo Tavg=0.0024785 | grep 'Tavg=' | grep -Eo \"[-+]?[0-9]*\\.?[0-9]+([eE][-+]?[0-9]+)?.\" | printf \"%f,\"\n",
    "# input_fn='/home/timothytyree/Documents/GitHub/bgmc/python/data/local_results/black_star_run_1_all/out.0'\n",
    "\n",
    "# df=pd.read_csv(input_fn)\n",
    "# #derived values\n",
    "# CollRate_missing=len(list(set(df.columns).intersection({'CollRate'})))==0\n",
    "# if CollRate_missing:\n",
    "#     df['CollRate']=1./df['CollTime']\n",
    "#     df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "#     df.dropna(subset=['CollRate'], how=\"all\",inplace=True)\n",
    "# df['A']=df['L']**2\n",
    "# df['q']=df['N']/df['A'] #number of tips per square centimeter\n",
    "# df['w']=df['CollRate']/df['A'] #[mHz?]/cm^2\n",
    "\n",
    "# plt.scatter(x=df.N.values,y=df.CollRate.values)\n",
    "# print(df.CollTime.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.071674Z",
     "start_time": "2022-02-07T20:57:16.066161Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #  0.003636 0.000607\n",
    "# # @what was it supposed to be?\n",
    "# 1/0.002538,1/0.002478"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "_A note on this data from the local pipeline__<br>\n",
    "this data from the local pipeline is not making sense... there's a million moving parts, and i have recently used the remote pipeline... Maybe they cross talked because they print helper files to the same directories... Yep... I'd bet that's causing the wonky reads.  I have verified the problem does not exist in the funcitonal string formatting...  Therefore, we have the courage to say...\n",
    "\n",
    "# __TODO:__ dev quick ar_star remote data run with 55 jobs gener_run_16.py and run it on the cloud!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T05:22:11.510939Z",
     "start_time": "2021-08-31T05:22:08.189Z"
    }
   },
   "source": [
    "# load the resulting table of powerlaw fits and perform interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.079590Z",
     "start_time": "2022-02-07T20:57:16.072973Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_466459/1028565047.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/local_results/black_star_run_1_all_powerlaw_fits.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_15_all_powerlaw_fits.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_19_all_powerlaw_fits.csv\"\n",
    "# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_17_all_powerlaw_fits.csv\"\n",
    "# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/local_results/black_star_run_1_all_powerlaw_fits.csv\"\n",
    "# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_15_all_powerlaw_fits.csv\"\n",
    "df=pd.read_csv(input_fn)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.080821Z",
     "start_time": "2022-02-07T20:57:16.080806Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(wjr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.081507Z",
     "start_time": "2022-02-07T20:57:16.081497Z"
    }
   },
   "outputs": [],
   "source": [
    "# df=df[df.niter==250].copy()\n",
    "#extract column values\n",
    "r_values=np.array(sorted(set(df.r.values)))#cm\n",
    "D_values=np.array(sorted(set(df.D.values)))#cm^2/s\n",
    "L_values=np.array(sorted(set(df.L.values)))#cm\n",
    "A_values=L_values**2#cm^2\n",
    "kappa_values=np.array(sorted(set(df.kappa.values)))#1/s\n",
    "varkappa_values=np.array(sorted(set(df.varkappa.values)))#1/s\n",
    "x0_values=np.array(sorted(set(df.x0.values)))#1/s\n",
    "set_second_values=np.array(sorted(set(df.set_second.values)))\n",
    "reflect_values=np.array(sorted(set(df.reflect.values)))\n",
    "no_repulsion_values=np.array(sorted(set(df.no_repulsion.values)))\n",
    "no_attraction_values=np.array(sorted(set(df.no_attraction.values)))\n",
    "neighbor_values=np.array(sorted(set(df.neighbor.values)))\n",
    "force_code_values=np.array(sorted(set(df.force_code.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.082218Z",
     "start_time": "2022-02-07T20:57:16.082207Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: make a fit of m as a function of r,kappa,D,varkappa,x0 for reflect==0\n",
    "#TODO: make a fit of M as a function of r,kappa,D,varkappa,x0 for reflect==0\n",
    "# fits to consider\n",
    "# - linear\n",
    "# - quadratic regression\n",
    "# - knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.091420Z",
     "start_time": "2022-02-07T20:57:16.083852Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_466459/2299661753.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#query the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_second\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mset_second\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreflect\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mreflect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m&=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_repulsion\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mno_repulsion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_attraction\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mno_attraction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m&=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbor\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mneighbor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_code\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mforce_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#define constant parameters\n",
    "neighbor=1\n",
    "# neighbor=0\n",
    "reflect=0\n",
    "force_code=2\n",
    "set_second=0\n",
    "no_attraction=0\n",
    "no_repulsion=0\n",
    "kappa=100\n",
    "L=10\n",
    "\n",
    "#query the DataFrame\n",
    "query =(df.set_second==set_second)&(df.reflect==reflect)\n",
    "query&=(df.no_repulsion==no_repulsion)&(df.no_attraction==no_attraction)\n",
    "query&=(df.neighbor==neighbor)&(df.force_code==force_code)\n",
    "# query&=df.r==r\n",
    "query&=df.kappa==kappa\n",
    "# query&=df.D==D\n",
    "query&=df.L==L\n",
    "# query&=df.varkappa==varkappa\n",
    "# query&=df.x0==x0\n",
    "dg=df[query]\n",
    "\n",
    "#define parameters to be varied\n",
    "input_cols=['r','D','varkappa']#,x0\n",
    "# input_cols=['r','kappa','D','varkappa']#,x0\n",
    "output_col='m'\n",
    "#inputs:dg,input_cols,output_col\n",
    "#output: fitted model\n",
    "\n",
    "Xall=dg[input_cols].values \n",
    "yall=dg[output_col].values\n",
    "X=Xall.copy()\n",
    "y=yall.copy()\n",
    "m = len(y) # number of training examples\n",
    "print(f'number of training examples is {m:d}.')\n",
    "\n",
    "interp = LinearNDInterpolator(X, y)\n",
    "# interp = CloughTocher2DInterpolator(X, y)\n",
    "yhat = interp(X)\n",
    "rmse=np.sqrt(np.mean((yhat-y)**2))\n",
    "print(f\"the rmse of simple interpolation is {rmse:.4f}\")\n",
    "\n",
    "# yhat = interp(X)\n",
    "print(f\"shape of X {X.shape} --> shape of y=yhat {yhat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.092338Z",
     "start_time": "2022-02-07T20:57:16.092328Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show only first 5 records\n",
    "print(f\"printing the first few trial results {input_cols}, y={output_col}\")\n",
    "for i in range(5):\n",
    "    print('X =', X[i], ',\\ty =', y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.093309Z",
     "start_time": "2022-02-07T20:57:16.093298Z"
    }
   },
   "outputs": [],
   "source": [
    "m_LR=wjr['lr_pbc']['m']\n",
    "\n",
    "#TODO: print apparent powerlaw exponent for these a values\n",
    "X_proj_LR=X.copy()\n",
    "amin_LR=8.5950-0.3771\n",
    "amax_LR=8.5950+0.3771\n",
    "X_proj_LR[:,-1]=X_proj_LR[:,-1]*0.+amin_LR\n",
    "mhat_min = interp(X_proj_LR)\n",
    "X_proj_LR[:,-1]=X_proj_LR[:,-1]*0.+amax_LR\n",
    "mhat_max = interp(X_proj_LR)\n",
    "plt.hist(mhat_min,color='C2',alpha=0.3,label='lower bound exponents',density=True)\n",
    "plt.hist(mhat_max,color='C3',alpha=0.3,label='upper bound exponents',density=True)\n",
    "format_plot(ax=plt.gca(),xlabel='power law exponent',ylabel='PDF')\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T21:57:11.884348Z",
     "start_time": "2021-11-17T21:57:11.851832Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## scratchwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.097973Z",
     "start_time": "2022-02-07T20:57:16.094444Z"
    },
    "hidden": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# #ordinary least squares is not helpful...\n",
    "# model_ols =  linear_model.LinearRegression(copy_X=True, fit_intercept=True)#, n_jobs=None, normalize=True)\n",
    "# # model_ols =  linear_model.LinearRegression(normalize=True)\n",
    "# model_ols.fit(X,y)\n",
    "# print('ordinary least squares is not helpful...')\n",
    "# print(f\"results of naive linear fitregression via ordinairy least squares:\")\n",
    "# coef = model_ols.coef_\n",
    "# intercept = model_ols.intercept_\n",
    "# print('coef= ', coef)\n",
    "# print('intercept= ', intercept)\n",
    "\n",
    "# Rsq=model_ols.score(X,y)\n",
    "# print(f\"Rsquared is {Rsq:.4f}\")\n",
    "\n",
    "# yhat=model_ols.predict(X)\n",
    "# rmse=np.sqrt(np.mean((yhat-y)**2))\n",
    "# print(f\"rmse is {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.103328Z",
     "start_time": "2022-02-07T20:57:16.099180Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#DONE: dev and test an inverse mapping from X_values to x1_values and x2_values\n",
    "#DONE: apply ^that same inverse mapping to y_values to ygrid_values\n",
    "\n",
    "#GOAL: make a beautiful analysis for WJR and PM\n",
    "#DONE: abstract the xaxis, D into x_col\n",
    "#DONE: in a backwards compatable way, swap a,r with D, and fix D instead\n",
    "#DONE: fix D=2 and kappa=500 and draw a versus r plot\n",
    "\n",
    "#DONE: chose reasonable colorbar values\n",
    "# #DONT(later, brief optimization of ^that colorbar): make the best color-contrasted heatmap plot of m versus a versus r (i.e. are versus-versus-plot abstractions)\n",
    "# #for fixed D=2\n",
    "# #for fixed kappa=250 Hz\n",
    "# # X_mesh=numpy 2d-array of pixel site values for a versus r\n",
    "# # y_value=the exponent, m. at each pixel site in X_mesh, m has values for the expected exponent from the powerlaw fit\n",
    "# vmin=avg_value-fwhm_value/2\n",
    "# vmax=avg_value+fwhm_value/2\n",
    "\n",
    "#DONE: plot level sets for the m,M from the LR model\n",
    "#DONE: identify any intersection points\n",
    "\n",
    "#TODO: plot level sets for the m,M from the FK model\n",
    "#TODO: identify any intersection points\n",
    "#TODO: repeat this for each kappa value observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.110523Z",
     "start_time": "2022-02-07T20:57:16.105214Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#TODO(reuse the \"genetic: algorithm I used previously that used random linear combinations via interp): guess many values of X that are a boltzman weighted linear combination of the top 6 + some normal error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.116032Z",
     "start_time": "2022-02-07T20:57:16.111797Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#DONE: compute a boltzman weighted mean of the top K=6\n",
    "#DONE: list the parameters r,kappa,D,a:=varkappa that have the closest exponent m to the LR model.  compute the boltzman weighted mean value\n",
    "#DONE: simulate the particle simulation locally/repeatably for the LR model. record.\n",
    "#DONE: rescale time such that the overall magnitude of the particle model is consistent with that of the LR model\n",
    "\n",
    "#TODO: list the parameters r,kappa,D,a:=varkappa that have the closest slope to the FK model\n",
    "#TODO: simulate the particle simulation locally/repeatably for the FK model. record\n",
    "#TODO: rescale time such that the overall magnitude of the particle model is consistent with that of the FK model\n",
    "\n",
    "#DONE: Plot these best fits\n",
    "#DONE: compute a boltzman weighted mean of the top K=6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.122907Z",
     "start_time": "2022-02-07T20:57:16.117028Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#TODO(for visualization): make a nice visualization using the previous method (just put a line plot of m,M versus a for several r values fixed, and an overall D value, also fixed)\n",
    "#TODO(later? for visualization): make a nice visualization using the new method\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# (optional) heatmaps of apparent powerfit parameters on D versus a\n",
    "- TODO(later): make another data run with more than 3 values of D used\n",
    "- TODO(later): make these into labeled contour plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.131619Z",
     "start_time": "2022-02-07T20:57:16.124287Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xall' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_466459/1506249053.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# unfixed_rows=[1,2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mboo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXall\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfixed_row\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mfixed_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXall\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mboo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# X[:,unfixed_rows[0]]=Xall[boo,unfixed_rows[0]].copy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Xall' is not defined"
     ]
    }
   ],
   "source": [
    "#solution for the r,D,a basis\n",
    "#restrict to fixed reaction range\n",
    "r=0.1 #cm\n",
    "fixed_value=r\n",
    "fixed_row=0\n",
    "\n",
    "# unfixed_rows=[1,2]\n",
    "boo=Xall[:,fixed_row]==fixed_value\n",
    "X=Xall[boo,1:3].copy()\n",
    "# X[:,unfixed_rows[0]]=Xall[boo,unfixed_rows[0]].copy()\n",
    "# X[:,unfixed_rows[1]]=Xall[boo,unfixed_rows[1]].copy()\n",
    "y=yall[boo].copy()\n",
    "\n",
    "#define the local grid for visualization of N-dim interpolation\n",
    "num_cols=X.shape[1]\n",
    "xi=[]\n",
    "for i in range(num_cols):\n",
    "    x=X[:,i]\n",
    "    xi.append( np.linspace(np.min(x), np.max(x)) )\n",
    "\n",
    "XI=np.meshgrid(*xi)\n",
    "print(len(XI))\n",
    "\n",
    "x1_values=XI[0]\n",
    "x2_values=XI[1]\n",
    "\n",
    "# np.array(list(zip(XI))).shape\n",
    "gridshape=x1_values.shape\n",
    "X_values=np.array(list(zip((x1_values.flatten(),x2_values.flatten()))))[:,fixed_row,:].T\n",
    "\n",
    "\n",
    "#TODO: compute the interpolated values of y on this 2D grid\n",
    "# interp = LinearNDInterpolator(X, y)\n",
    "interp = CloughTocher2DInterpolator(X, y)\n",
    "y_values = interp(X_values).reshape(gridshape[0],gridshape[1])\n",
    "y_values.shape\n",
    "# ,X_values.shape,x1_values.shape\n",
    "# y_values.reshape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.132684Z",
     "start_time": "2022-02-07T20:57:16.132673Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#plot the interpolated m (left) and the interpolated M (right) for each pixel.\n",
    "#visualize a versus D\n",
    "x2lim=[0,30]\n",
    "# x2lim=[0,110]\n",
    "x1lim=[0.7,2]#[np.min(x1_values),np.max(x1_values)]\n",
    "# x1lim=[np.min(x1_values),np.max(x1_values)]\n",
    "fontsize=15\n",
    "xlabel=r'$D$ (cm$^2$/s)'\n",
    "ylabel=r'$a$ (cm$^2$/s)'\n",
    "cmap = mpl.cm.cool\n",
    "\n",
    "Xall=dg[input_cols].values \n",
    "\n",
    "#define parameters to be varied\n",
    "input_cols=['r','D','varkappa']#,x0\n",
    "# input_cols=['r','kappa','D','varkappa']#,x0\n",
    "# output_col='m'\n",
    "#inputs:dg,input_cols,output_col\n",
    "#output: fitted model\n",
    "\n",
    "#columnal kwargs\n",
    "vmin_lst=[1,0]\n",
    "vmax_lst=[3,30]\n",
    "# output_col_lst=['Delta_m','Rsq']\n",
    "output_col_lst=['m','M']\n",
    "#kwargs by row\n",
    "r_lst=[0.1,0.2]\n",
    "fig, axs = plt.subplots(2, len(r_lst), figsize=(16,14))\n",
    "cmaps = ['RdBu_r', 'viridis']\n",
    "title_foo=lambda r:f'r = {r:.1f} cm'\n",
    "nsamples=1000\n",
    "for col in range(len(output_col_lst)):\n",
    "    #extract target output value to fit to\n",
    "    output_col=output_col_lst[col]\n",
    "    yall=dg[output_col].values\n",
    "    for row in range(2):\n",
    "        #restrict to fixed reaction range\n",
    "        r=r_lst[row]\n",
    "        title=title_foo(r)#f'r = {r:.1f} cm'\n",
    "        boo=Xall[:,0]==r\n",
    "        X=Xall[boo,1:3].copy()  #make the x,y axis the 2nd and 3rd columns of X\n",
    "        y=yall[boo].copy()\n",
    "        #TODO: compute the m,M fits\n",
    "        #TODO: compute the interpolated values of y on this 2D grid\n",
    "        interp = LinearNDInterpolator(X, y)\n",
    "        interp = CloughTocher2DInterpolator(X, y)\n",
    "\n",
    "        #define the local grid for visualization of N-dim interpolation\n",
    "        num_cols=X.shape[1]\n",
    "        xi=[]\n",
    "        for i in range(num_cols):\n",
    "            x=X[:,i]\n",
    "            xi.append( np.linspace(np.min(x), np.max(x),nsamples) )\n",
    "\n",
    "        XI=np.meshgrid(*xi)\n",
    "        x1_values=XI[0]\n",
    "        x2_values=XI[1]\n",
    "\n",
    "        # np.array(list(zip(XI))).shape\n",
    "        gridshape=x1_values.shape\n",
    "        X_values =np.array(list(zip((x1_values.flatten(),x2_values.flatten()))))[:,0,:].T\n",
    "        y_values = interp(X_values).reshape(gridshape[0],gridshape[1]) \n",
    "        \n",
    "        ax = axs[row, col]\n",
    "        vmin=vmin_lst[col]\n",
    "        vmax=vmax_lst[col]\n",
    "#         vmin=np.quantile(y_values.flatten(),0.25)\n",
    "#         vmax=np.quantile(y_values.flatten(),0.75)\n",
    "        pcm=ax.pcolormesh(x1_values, x2_values, y_values, vmin=vmin, vmax=vmax, cmap=cmaps[col])\n",
    "        \n",
    "        \n",
    "#         ax.set_xlim(x1lim)\n",
    "#         ax.set_ylim(x2lim)\n",
    "        ax.set_title(title,fontsize=fontsize)\n",
    "        format_plot(ax, xlabel, ylabel, fontsize)#, use_loglog=False\n",
    "        \n",
    "#     fig.colorbar(pcm, ax=[axs[0, col]], location='top', shrink=0.6)\n",
    "    cbar=fig.colorbar(pcm, ax=axs[:, col],shrink=0.6)#,label=output_col)\n",
    "    cbar.ax.tick_params(labelsize=fontsize)\n",
    "    cbar.set_label(output_col, fontsize=fontsize)    \n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.133335Z",
     "start_time": "2022-02-07T20:57:16.133325Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#TODO./DONE_up_^there: fit interp on all dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T20:14:20.414168Z",
     "start_time": "2021-09-14T20:14:20.391136Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.134057Z",
     "start_time": "2022-02-07T20:57:16.134047Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x2lim=[0,20]\n",
    "# x1lim=[np.min(x1_values),np.max(x1_values)]\n",
    "# fontsize=20\n",
    "# # xlabel=r'$r$ (cm)'\n",
    "# xlabel=r'$D$ (cm$^2$/s)'\n",
    "# ylabel=r'$a$ (cm$^2$/s)'\n",
    "# vmin=1\n",
    "# vmax=3\n",
    "# cmap = mpl.cm.cool\n",
    "\n",
    "# #TODO:visualize this slice\n",
    "# fig, ax = plt.subplots(figsize=(6, 4))\n",
    "# # ax.pcolormesh(x1_values, x2_values, y_values, shading='auto')\n",
    "# ax.pcolormesh(x1_values, x2_values, y_values, vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "\n",
    "\n",
    "# # # #format for colorbar\n",
    "# # # # fig.subplots_adjust(bottom=0.5)\n",
    "# # norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "# # fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "# #              cax=ax, orientation='vertical', label='exponent value')\n",
    "\n",
    "\n",
    "# ax.set_xlim(x1lim)\n",
    "# ax.set_ylim(x2lim)\n",
    "# format_plot(ax, xlabel, ylabel, fontsize)#, use_loglog=False\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.134783Z",
     "start_time": "2022-02-07T20:57:16.134772Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# x1lim=[0.05,0.5]#r\n",
    "# x2lim=[0,20]#a\n",
    "# # x1lim=[0.7,2]#D [np.min(x1_values),np.max(x1_values)]\n",
    "# # x1lim=[np.min(x1_values),np.max(x1_values)]\n",
    "# fontsize=15\n",
    "# xlabel=r'$r$ (cm)'\n",
    "# xlabel=r'$D$ (cm$^2$/s)'\n",
    "# # ylabel=r'$a$ (cm$^2$/s)'\n",
    "# cmap = mpl.cm.cool\n",
    "\n",
    "# #TODO: compute the interpolated m (left) and the interpolated M (right) for each pixel.\n",
    "# #HINT: if col==0: # then, get fitted m values\n",
    "# #HINT: if col==1: # then, get fitted M values\n",
    "\n",
    "\n",
    "# #define parameters to be varied\n",
    "# input_cols=['r','D','varkappa']#,x0\n",
    "# # input_cols=['r','kappa','D','varkappa']#,x0\n",
    "# # output_col='m'\n",
    "# #inputs:dg,input_cols,output_col\n",
    "# #output: fitted model\n",
    "\n",
    "# Xall=dg[input_cols].values \n",
    "# #D=2\n",
    "# #columnal kwargs\n",
    "# vmin_lst=[1,0]\n",
    "# vmax_lst=[3,30]\n",
    "# output_col_lst=['m','M']\n",
    "# #kwargs by row\n",
    "# r_lst=[0.1,0.2]\n",
    "# colvar_lst=r_lst\n",
    "# title_foo=lambda r:f'r = {r:.1f} cm'\n",
    "# # kappa_lst=[250,500]\n",
    "# # colvar_lst=kappa_lst\n",
    "# # title_foo=lambda kappa:f'kappa = {kappa:.1f} cm'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.137534Z",
     "start_time": "2022-02-07T20:57:16.135781Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#TODO(for visualization): make a nice visualization using the previous method (just put a line plot of m,M versus a for several r values fixed, and an overall D value, also fixed)\n",
    "#TODO(later? for visualization): make a nice visualization using the new method \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# fix D. fix kappa. Plot the heatmap of m value over a versus r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.149471Z",
     "start_time": "2022-02-07T20:57:16.139989Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_466459/351811865.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#query the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_second\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mset_second\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreflect\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mreflect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m&=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_repulsion\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mno_repulsion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_attraction\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mno_attraction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m&=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbor\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mneighbor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_code\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mforce_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "neighbor=1\n",
    "# neighbor=0\n",
    "#define constant parameters\n",
    "reflect=0\n",
    "force_code=2\n",
    "set_second=0\n",
    "no_attraction=0\n",
    "no_repulsion=0\n",
    "kappa=500\n",
    "L=10\n",
    "\n",
    "#query the DataFrame\n",
    "query =(df.set_second==set_second)&(df.reflect==reflect)\n",
    "query&=(df.no_repulsion==no_repulsion)&(df.no_attraction==no_attraction)\n",
    "query&=(df.neighbor==neighbor)&(df.force_code==force_code)\n",
    "# query&=df.r==r\n",
    "# query&=df.kappa==kappa\n",
    "# query&=df.D==D\n",
    "query&=df.L==L\n",
    "# query&=df.varkappa==varkappa\n",
    "# query&=df.x0==x0\n",
    "query_template=query.copy()\n",
    "dg=df[query]\n",
    "\n",
    "#define parameters to be varied\n",
    "# input_cols=['r','D','varkappa']#,x0\n",
    "input_cols=['r','kappa','D','varkappa']#,x0\n",
    "output_col='m'\n",
    "#inputs:dg,input_cols,output_col\n",
    "#output: fitted model\n",
    "\n",
    "Xall=dg[input_cols].values \n",
    "yall=dg[output_col].values\n",
    "X=Xall.copy()\n",
    "y=yall.copy()\n",
    "m = len(y) # number of training examples\n",
    "print(f'number of training examples is {m:d}.')\n",
    "\n",
    "interp = LinearNDInterpolator(X, y)\n",
    "# interp = CloughTocher2DInterpolator(X, y)\n",
    "yhat = interp(X)\n",
    "rmse=np.sqrt(np.mean((yhat-y)**2))\n",
    "print(f\"the rmse of linear interpolation is {rmse:.4f}\")\n",
    "\n",
    "# yhat = interp(X)\n",
    "print(f\"shape of X {X.shape} --> shape of y=yhat {yhat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.150671Z",
     "start_time": "2022-02-07T20:57:16.150661Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D=0.3\n",
    "# D=2\n",
    "#visualize a versus r\n",
    "x1lim=[0.05,0.5]\n",
    "x2lim=[1,50]\n",
    "# x2lim=[0,50]\n",
    "fontsize=16\n",
    "figsize=(11,4.5)#(16,6)#(16,14)\n",
    "xlabel=r'$r$ (cm)'\n",
    "ylabel=r'$a$ (cm$^2$/s)'\n",
    "cmap = mpl.cm.cool\n",
    "#columnal kwargs\n",
    "vmin_lst=[1,1]\n",
    "vmax_lst=[3,3]\n",
    "# vmin_lst=[1,0]\n",
    "# vmax_lst=[3,20]\n",
    "output_col_lst=['m','m']\n",
    "# output_col_lst=['m','M']\n",
    "#kwargs by row\n",
    "# r_lst=[0.1,0.2]\n",
    "kappa_lst=[250,500]\n",
    "kappa_col=2\n",
    "cmaps = ['RdBu_r', 'RdBu_r']\n",
    "# cmaps = ['RdBu_r', 'viridis']\n",
    "title_foo=lambda kappa:f'kappa = {kappa:.0f} Hz'\n",
    "# fig,ax=plt.subplots()\n",
    "fig,axs=plt.subplots(ncols=2, figsize=figsize)\n",
    "# fig, axs = plt.subplots(2, len(kappa_lst), figsize=(16,14))\n",
    "# kappa=500\n",
    "nsamples=1000\n",
    "col=0\n",
    "kappa_lst=[250,500]\n",
    "for col,kappa in enumerate(kappa_lst):\n",
    "    output_col=output_col_lst[col]\n",
    "    query = (df['D']==D)\n",
    "    query&= (df['kappa']==kappa)\n",
    "    query&= query_template\n",
    "    X=df.loc[query,['r','varkappa']].values\n",
    "    y_values=df.loc[query,output_col].values\n",
    "#     interp = LinearNDInterpolator(X, y_values)\n",
    "    interp = CloughTocher2DInterpolator(X, y_values)\n",
    "\n",
    "    #TODO: make interpolator that maps X to y values everywhere\n",
    "    #TODO: make a grid realization of y_values\n",
    "    #TODO: how do I compute y_values previously?\n",
    "    #TODO: could this be as easy as a nested for-loop about each pixel value, running y_values=interp(X[j,:])\n",
    "\n",
    "    #define the local grid for visualization of N-dim interpolation\n",
    "    num_cols=X.shape[1]\n",
    "    xi=[]\n",
    "    for i in range(num_cols):\n",
    "        x=X[:,i]\n",
    "        xi.append( np.linspace(np.min(x), np.max(x),nsamples) )\n",
    "    XI=np.meshgrid(*xi)\n",
    "    print(len(XI))\n",
    "    x1_values=XI[0]\n",
    "    x2_values=XI[1]\n",
    "\n",
    "    # np.array(list(zip(XI))).shape\n",
    "    gridshape=x1_values.shape\n",
    "    X_values =np.array(list(zip((x1_values.flatten(),x2_values.flatten()))))[:,0,:].T\n",
    "    print(X_values.shape)\n",
    "    y_values = interp(X_values).reshape(gridshape[0],gridshape[1]) \n",
    "    # y_values = interp(X_values).reshape(gridshape[0],gridshape[1]) \n",
    "    print((x1_values.shape,x2_values.shape,y_values.shape))\n",
    "    ax=axs[col]\n",
    "    #ax = axs[row, col]\n",
    "    #     #plot heatmap in the next axis\n",
    "    #     #ax = axs[row, col]\n",
    "    vmin=vmin_lst[col]\n",
    "    vmax=vmax_lst[col]\n",
    "    pcm=ax.pcolormesh(x1_values, x2_values, y_values, vmin=vmin, vmax=vmax, cmap=cmaps[col])\n",
    "#     pcm=ax.pcolormesh(np.log(x1_values+1), np.log(x2_values+1), y_values, vmin=vmin, vmax=vmax, cmap=cmaps[col])\n",
    "    ax.set_xlim(x1lim)\n",
    "    ax.set_ylim(x2lim)\n",
    "    title=title_foo(kappa)\n",
    "    ax.set_title(title,fontsize=fontsize)\n",
    "    format_plot(ax, xlabel, ylabel, fontsize, use_loglog=False)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    cbar=fig.colorbar(pcm, ax=ax, shrink=0.6,label=output_col)#, location='top'\n",
    "    # fig.colorbar(pcm, ax=[axs[0, col]], location='top', shrink=0.6)\n",
    "    #     cbar=fig.colorbar(pcm, ax=axs[:, col],shrink=0.6)#,label=output_col)\n",
    "    cbar.ax.tick_params(labelsize=fontsize)\n",
    "    cbar.set_label(output_col, fontsize=fontsize)    \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.151604Z",
     "start_time": "2022-02-07T20:57:16.151593Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#visualize a versus r\n",
    "x1lim=[0.05,0.5]\n",
    "x2lim=[1,50]\n",
    "# x2lim=[0,50]\n",
    "fontsize=16\n",
    "figsize=(11,4.5)#(16,6)#(16,14)\n",
    "xlabel=r'$r$ (cm)'\n",
    "ylabel=r'$a$ (cm$^2$/s)'\n",
    "cmap = mpl.cm.cool\n",
    "#columnal kwargs\n",
    "# vmin_lst=[1,1]\n",
    "# vmax_lst=[3,3]\n",
    "vmin_lst=[0,0]\n",
    "vmax_lst=[30,30]\n",
    "output_col_lst=['M','M']\n",
    "# output_col_lst=['m','M']\n",
    "#kwargs by row\n",
    "# r_lst=[0.1,0.2]\n",
    "kappa_lst=[250,500]\n",
    "kappa_col=2\n",
    "# cmaps = ['RdBu_r', 'RdBu_r']\n",
    "cmaps = ['viridis', 'viridis']\n",
    "title_foo=lambda kappa:f'kappa = {kappa:.0f} Hz'\n",
    "# fig,ax=plt.subplots()\n",
    "fig,axs=plt.subplots(ncols=2, figsize=figsize)\n",
    "# fig, axs = plt.subplots(2, len(kappa_lst), figsize=(16,14))\n",
    "# D=2.0\n",
    "# kappa=500\n",
    "nsamples=1000\n",
    "col=0\n",
    "kappa_lst=[250,500]\n",
    "for col,kappa in enumerate(kappa_lst):\n",
    "    output_col=output_col_lst[col]\n",
    "    query = (df['D']==D)\n",
    "    query&= (df['kappa']==kappa)\n",
    "    query&= query_template\n",
    "    X=df.loc[query,['r','varkappa']].values\n",
    "    y_values=df.loc[query,output_col].values\n",
    "    interp = LinearNDInterpolator(X, y_values)\n",
    "    # interp = CloughTocher2DInterpolator(X, y_values)\n",
    "\n",
    "    #TODO: make interpolator that maps X to y values everywhere\n",
    "    #TODO: make a grid realization of y_values\n",
    "    #TODO: how do I compute y_values previously?\n",
    "    #TODO: could this be as easy as a nested for-loop about each pixel value, running y_values=interp(X[j,:])\n",
    "\n",
    "    #define the local grid for visualization of N-dim interpolation\n",
    "    num_cols=X.shape[1]\n",
    "    xi=[]\n",
    "    for i in range(num_cols):\n",
    "        x=X[:,i]\n",
    "        xi.append( np.linspace(np.min(x), np.max(x),nsamples) )\n",
    "    XI=np.meshgrid(*xi)\n",
    "    print(len(XI))\n",
    "    x1_values=XI[0]\n",
    "    x2_values=XI[1]\n",
    "\n",
    "    # np.array(list(zip(XI))).shape\n",
    "    gridshape=x1_values.shape\n",
    "    X_values =np.array(list(zip((x1_values.flatten(),x2_values.flatten()))))[:,0,:].T\n",
    "    print(X_values.shape)\n",
    "    y_values = interp(X_values).reshape(gridshape[0],gridshape[1]) \n",
    "    # y_values = interp(X_values).reshape(gridshape[0],gridshape[1]) \n",
    "    print((x1_values.shape,x2_values.shape,y_values.shape))\n",
    "    ax=axs[col]\n",
    "    #ax = axs[row, col]\n",
    "    #     #plot heatmap in the next axis\n",
    "    #     #ax = axs[row, col]\n",
    "    vmin=vmin_lst[col]\n",
    "    vmax=vmax_lst[col]\n",
    "    pcm=ax.pcolormesh(x1_values, x2_values, y_values, vmin=vmin, vmax=vmax, cmap=cmaps[col])\n",
    "#     pcm=ax.pcolormesh(np.log(x1_values+1), np.log(x2_values+1), y_values, vmin=vmin, vmax=vmax, cmap=cmaps[col])\n",
    "    ax.set_xlim(x1lim)\n",
    "    ax.set_ylim(x2lim)\n",
    "    title=title_foo(kappa)\n",
    "    ax.set_title(title,fontsize=fontsize)\n",
    "    format_plot(ax, xlabel, ylabel, fontsize, use_loglog=False)\n",
    "    ax.set_xscale('log')\n",
    "#     ax.set_yscale('log')\n",
    "    cbar=fig.colorbar(pcm, ax=ax, shrink=0.6,label=output_col)#, location='top'\n",
    "    # fig.colorbar(pcm, ax=[axs[0, col]], location='top', shrink=0.6)\n",
    "    #     cbar=fig.colorbar(pcm, ax=axs[:, col],shrink=0.6)#,label=output_col)\n",
    "    cbar.ax.tick_params(labelsize=fontsize)\n",
    "    cbar.set_label(output_col, fontsize=fontsize)    \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.163585Z",
     "start_time": "2022-02-07T20:57:16.152647Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mpl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_466459/2969576243.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mxlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mr'$r$ (cm)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mylabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mr'$a$ (cm$^2$/s)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#columnal kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# vmin_lst=[1,1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mpl' is not defined"
     ]
    }
   ],
   "source": [
    "#visualize a versus r\n",
    "x1lim=[0.05,0.5]\n",
    "x2lim=[1,50]\n",
    "# x2lim=[0,50]\n",
    "fontsize=16\n",
    "figsize=(11,4.5)#(16,6)#(16,14)\n",
    "xlabel=r'$r$ (cm)'\n",
    "ylabel=r'$a$ (cm$^2$/s)'\n",
    "cmap = mpl.cm.cool\n",
    "#columnal kwargs\n",
    "# vmin_lst=[1,1]\n",
    "# vmax_lst=[3,3]\n",
    "vmin_lst=[0,0]\n",
    "vmax_lst=[30,30]\n",
    "output_col_lst=['M','M']\n",
    "# output_col_lst=['m','M']\n",
    "#kwargs by row\n",
    "# r_lst=[0.1,0.2]\n",
    "kappa_lst=[250,500]\n",
    "kappa_col=2\n",
    "# cmaps = ['RdBu_r', 'RdBu_r']\n",
    "cmaps = ['viridis', 'viridis']\n",
    "title_foo=lambda kappa:f'kappa = {kappa:.0f} Hz'\n",
    "# fig,ax=plt.subplots()\n",
    "fig,axs=plt.subplots(ncols=2, figsize=figsize)\n",
    "# fig, axs = plt.subplots(2, len(kappa_lst), figsize=(16,14))\n",
    "# D=2.0\n",
    "# kappa=500\n",
    "nsamples=1000\n",
    "col=0\n",
    "kappa_lst=[250,500]\n",
    "for col,kappa in enumerate(kappa_lst):\n",
    "    output_col=output_col_lst[col]\n",
    "    query = (df['D']==D)\n",
    "    query&= (df['kappa']==kappa)\n",
    "    query&= query_template\n",
    "    X=df.loc[query,['r','varkappa']].values\n",
    "    y_values=df.loc[query,output_col].values\n",
    "    interp = LinearNDInterpolator(X, y_values)\n",
    "    # interp = CloughTocher2DInterpolator(X, y_values)\n",
    "\n",
    "    #TODO: make interpolator that maps X to y values everywhere\n",
    "    #TODO: make a grid realization of y_values\n",
    "    #TODO: how do I compute y_values previously?\n",
    "    #TODO: could this be as easy as a nested for-loop about each pixel value, running y_values=interp(X[j,:])\n",
    "\n",
    "    #define the local grid for visualization of N-dim interpolation\n",
    "    num_cols=X.shape[1]\n",
    "    xi=[]\n",
    "    for i in range(num_cols):\n",
    "        x=X[:,i]\n",
    "        xi.append( np.linspace(np.min(x), np.max(x),nsamples) )\n",
    "    XI=np.meshgrid(*xi)\n",
    "    print(len(XI))\n",
    "    x1_values=XI[0]\n",
    "    x2_values=XI[1]\n",
    "\n",
    "    # np.array(list(zip(XI))).shape\n",
    "    gridshape=x1_values.shape\n",
    "    X_values =np.array(list(zip((x1_values.flatten(),x2_values.flatten()))))[:,0,:].T\n",
    "    print(X_values.shape)\n",
    "    y_values = interp(X_values).reshape(gridshape[0],gridshape[1]) \n",
    "    # y_values = interp(X_values).reshape(gridshape[0],gridshape[1]) \n",
    "    print((x1_values.shape,x2_values.shape,y_values.shape))\n",
    "    ax=axs[col]\n",
    "    #ax = axs[row, col]\n",
    "    #     #plot heatmap in the next axis\n",
    "    #     #ax = axs[row, col]\n",
    "    vmin=vmin_lst[col]\n",
    "    vmax=vmax_lst[col]\n",
    "    pcm=ax.pcolormesh(x1_values, x2_values, y_values, vmin=vmin, vmax=vmax, cmap=cmaps[col])\n",
    "#     pcm=ax.pcolormesh(np.log(x1_values+1), np.log(x2_values+1), y_values, vmin=vmin, vmax=vmax, cmap=cmaps[col])\n",
    "    ax.set_xlim(x1lim)\n",
    "    ax.set_ylim(x2lim)\n",
    "    title=title_foo(kappa)\n",
    "    ax.set_title(title,fontsize=fontsize)\n",
    "    format_plot(ax, xlabel, ylabel, fontsize, use_loglog=False)\n",
    "#     ax.set_xscale('log')\n",
    "#     ax.set_yscale('log')\n",
    "    cbar=fig.colorbar(pcm, ax=ax, shrink=0.6,label=output_col)#, location='top'\n",
    "    # fig.colorbar(pcm, ax=[axs[0, col]], location='top', shrink=0.6)\n",
    "    #     cbar=fig.colorbar(pcm, ax=axs[:, col],shrink=0.6)#,label=output_col)\n",
    "    cbar.ax.tick_params(labelsize=fontsize)\n",
    "    cbar.set_label(output_col, fontsize=fontsize)    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.164565Z",
     "start_time": "2022-02-07T20:57:16.164554Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# contours = plt.contour(x1_values, x2_values, y_values, 3, colors='black')\n",
    "# plt.clabel(contours, inline=True, fontsize=8)\n",
    "\n",
    "# plt.imshow(y_values, extent=[0.05, 0.5, 0, 50], origin='lower',\n",
    "#            cmap='RdGy', alpha=0.5)\n",
    "# # plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.164971Z",
     "start_time": "2022-02-07T20:57:16.164961Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comp_longest_level_set_and_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## der scratchwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.165935Z",
     "start_time": "2022-02-07T20:57:16.165925Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #TODO: for a given local m measure in the r,a plane, compute the lewiner level set for a square lattice via the lookup-table implementation.\n",
    "\n",
    "# #GOAL: level sets\n",
    "# #TODO: copy existing method of level sets here!!!\n",
    "# #heretim\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# X.shape,y_values.shape\n",
    "\n",
    "# #  plot heatmap in the next axis\n",
    "# #ax = axs[row, col]\n",
    "# #     vmin=vmin_lst[col]\n",
    "# #     vmax=vmax_lst[col]\n",
    "# pcm=ax.pcolormesh(x1_values, x2_values, y_values)#, vmin=vmin, vmax=vmax, cmap=cmaps[col])\n",
    "\n",
    "\n",
    "# X.shape,x1_values.shape,x2_values.shape,y_values.shape\n",
    "\n",
    "# #define parameters to be varied\n",
    "# # input_cols=['r','D','varkappa']#,x0\n",
    "# input_cols=['r','kappa','D','varkappa']#,x0\n",
    "# output_col='m'\n",
    "# #inputs:dg,input_cols,output_col\n",
    "# #output: fitted model\n",
    "\n",
    "# #solution for the r,D,a basis\n",
    "# #restrict to fixed reaction range\n",
    "# # r=0.1 #cm\n",
    "# D=2\n",
    "# fixed_value=D#r\n",
    "# fixed_row=1\n",
    "\n",
    "# unfixed_rows=[0,2]\n",
    "# boo=Xall[:,fixed_row]==fixed_value\n",
    "# X=Xall[boo,1:3].copy()\n",
    "# X[:,0]=Xall[boo,unfixed_rows[0]].copy()\n",
    "# X[:,1]=Xall[boo,unfixed_rows[1]].copy()\n",
    "# X[:,1]=Xall[boo,unfixed_rows[1]].copy()\n",
    "# y=yall[boo].copy()\n",
    "\n",
    "# #define the local grid for visualization of N-dim interpolation\n",
    "# num_cols=X.shape[1]\n",
    "# xi=[]\n",
    "# for i in range(num_cols):\n",
    "#     x=X[:,i]\n",
    "#     xi.append( np.linspace(np.min(x), np.max(x)) )\n",
    "\n",
    "# XI=np.meshgrid(*xi)\n",
    "# print(len(XI))\n",
    "\n",
    "# x1_values=XI[0]\n",
    "# x2_values=XI[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         #heretim\n",
    "#         X=Xall[boo,1:3].copy()  #make the x,y axis the 2nd and 3rd columns of X\n",
    "#         y=yall[boo].copy()\n",
    "#         #TODO: compute the m,M fits\n",
    "#         #TODO: compute the interpolated values of y on this 2D grid\n",
    "#         # interp = LinearNDInterpolator(X, y)\n",
    "#         interp = CloughTocher2DInterpolator(X, y)\n",
    "\n",
    "#         #define the local grid for visualization of N-dim interpolation\n",
    "#         num_cols=X.shape[1]\n",
    "#         xi=[]\n",
    "#         for i in range(num_cols):\n",
    "#             x=X[:,i]\n",
    "#             xi.append( np.linspace(np.min(x), np.max(x)) )\n",
    "#         XI=np.meshgrid(*xi)\n",
    "#         x1_values=XI[0]\n",
    "#         x2_values=XI[1]\n",
    "\n",
    "#         # np.array(list(zip(XI))).shape\n",
    "#         gridshape=x1_values.shape\n",
    "#         X_values =np.array(list(zip((x1_values.flatten(),x2_values.flatten()))))[:,0,:].T\n",
    "#         y_values = interp(X_values).reshape(gridshape[0],gridshape[1]) \n",
    "        \n",
    "#         ax = axs[row, col]\n",
    "#         vmin=vmin_lst[col]\n",
    "#         vmax=vmax_lst[col]\n",
    "#         pcm=ax.pcolormesh(x1_values, x2_values, y_values, vmin=vmin, vmax=vmax, cmap=cmaps[col])\n",
    "       \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# # np.array(list(zip(XI))).shape\n",
    "# gridshape=x1_values.shape\n",
    "# X_values=np.array(list(zip((x1_values.flatten(),x2_values.flatten()))))[:,0,:].T\n",
    "\n",
    "\n",
    "# #TODO: compute the interpolated values of y on this 2D grid\n",
    "# # interp = LinearNDInterpolator(X, y)\n",
    "# interp = CloughTocher2DInterpolator(X, y)\n",
    "# y_values = interp(X_values).reshape(gridshape[0],gridshape[1])\n",
    "# y_values.shape\n",
    "# # ,X_values.shape,x1_values.shape\n",
    "# # y_values.reshape?\n",
    "\n",
    "# #visualize a versus r\n",
    "# x2lim=[0,20]\n",
    "# x1lim=[0.05,0.5]#[np.min(x1_values),np.max(x1_values)]\n",
    "# # x1lim=[np.min(x1_values),np.max(x1_values)]\n",
    "# fontsize=15\n",
    "# xlabel=r'$r$ (cm)'\n",
    "# ylabel=r'$a$ (cm$^2$/s)'\n",
    "# cmap = mpl.cm.cool\n",
    "\n",
    "# #TODO: compute the interpolated m (left) and the interpolated M (right) for each pixel.\n",
    "# #HINT: if col==0: # then, get fitted m values\n",
    "# #HINT: if col==1: # then, get fitted M values\n",
    "\n",
    "# Xall=dg[input_cols].values \n",
    "\n",
    "# #columnal kwargs\n",
    "# vmin_lst=[1,0]\n",
    "# vmax_lst=[3,30]\n",
    "# output_col_lst=['m','M']\n",
    "# #kwargs by row\n",
    "# # r_lst=[0.1,0.2]\n",
    "# kappa_lst=[250,500]\n",
    "# kappa_col=2\n",
    "# fig, axs = plt.subplots(2, len(kappa_lst), figsize=(16,14))\n",
    "# cmaps = ['RdBu_r', 'viridis']\n",
    "# title_foo=lambda kappa:f'kappa = {kappa:.1f} Hz'\n",
    "\n",
    "# for col in range(2):\n",
    "#     #extract target output value to fit to\n",
    "#     output_col=output_col_lst[col]\n",
    "#     yall=dg[output_col].values\n",
    "#     for row in range(2):\n",
    "#         #restrict to fixed reaction range\n",
    "#         kappa=kappa_lst[row]\n",
    "#         title=title_foo(kappa)#f'r = {r:.1f} cm'\n",
    "#         boo=Xall[:,kappa_col]==kappa\n",
    "        \n",
    "        \n",
    "#         #heretim\n",
    "#         X=Xall[boo,1:3].copy()  #make the x,y axis the 2nd and 3rd columns of X\n",
    "#         y=yall[boo].copy()\n",
    "#         #TODO: compute the m,M fits\n",
    "#         #TODO: compute the interpolated values of y on this 2D grid\n",
    "#         # interp = LinearNDInterpolator(X, y)\n",
    "#         interp = CloughTocher2DInterpolator(X, y)\n",
    "\n",
    "#         #define the local grid for visualization of N-dim interpolation\n",
    "#         num_cols=X.shape[1]\n",
    "#         xi=[]\n",
    "#         for i in range(num_cols):\n",
    "#             x=X[:,i]\n",
    "#             xi.append( np.linspace(np.min(x), np.max(x)) )\n",
    "#         XI=np.meshgrid(*xi)\n",
    "#         x1_values=XI[0]\n",
    "#         x2_values=XI[1]\n",
    "\n",
    "#         # np.array(list(zip(XI))).shape\n",
    "#         gridshape=x1_values.shape\n",
    "#         X_values =np.array(list(zip((x1_values.flatten(),x2_values.flatten()))))[:,0,:].T\n",
    "#         y_values = interp(X_values).reshape(gridshape[0],gridshape[1]) \n",
    "        \n",
    "#         ax = axs[row, col]\n",
    "#         vmin=vmin_lst[col]\n",
    "#         vmax=vmax_lst[col]\n",
    "#         pcm=ax.pcolormesh(x1_values, x2_values, y_values, vmin=vmin, vmax=vmax, cmap=cmaps[col])\n",
    "        \n",
    "        \n",
    "#         ax.set_xlim(x1lim)\n",
    "#         ax.set_ylim(x2lim)\n",
    "#         ax.set_title(title,fontsize=fontsize)\n",
    "#         format_plot(ax, xlabel, ylabel, fontsize)#, use_loglog=False\n",
    "        \n",
    "# #     fig.colorbar(pcm, ax=[axs[0, col]], location='top', shrink=0.6)\n",
    "#     cbar=fig.colorbar(pcm, ax=axs[:, col],shrink=0.6)#,label=output_col)\n",
    "#     cbar.ax.tick_params(labelsize=fontsize)\n",
    "#     cbar.set_label(output_col, fontsize=fontsize)    \n",
    "# # plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select the top K=6 trials of r,D,a values most reasonable for the powerlaw fits from the full models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## DONE: make this comp_ND_interpolation routine functional and move to lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.172145Z",
     "start_time": "2022-02-07T20:57:16.169648Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #TODO: move this into lib for the boltzaman weighted mean routine\n",
    "# def comp_ND_interpolation(dg,input_cols,output_col,**kwargs):\n",
    "#     \"\"\"inputs:dg,input_cols,output_col\n",
    "#         output: fitted model\n",
    "#     dg=df[query] is a pandas.DataFrame instance assumed to have a unique trial \n",
    "#     for any unique combination of fields indicated by input_col\n",
    "#     define parameters to be varied\n",
    "#     input_cols=['r','D','varkappa']#,x0\n",
    "#     input_cols=['r','kappa','D','varkappa']#,x0\n",
    "    \n",
    "#     Example Usage:\n",
    "#     interp=comp_ND_interpolation(dg,input_cols,output_col)\n",
    "#     \"\"\"\n",
    "\n",
    "#     Xall=dg[input_cols].values \n",
    "#     yall=dg[output_col].values\n",
    "#     X=Xall.copy()\n",
    "#     y=yall.copy()\n",
    "#     m = len(y) # number of training examples\n",
    "#     print(f'the number of training examples is {m:d}')\n",
    "#     try:\n",
    "#         interp = LinearNDInterpolator(X, y)\n",
    "#         yhat = interp(X)\n",
    "#         rmse=np.sqrt(np.mean((yhat-y)**2))\n",
    "#     except Exception as e:\n",
    "#         #print('Warning: '+e) #QhullError...\n",
    "#         interp = LinearNDInterpolator(X, y)\n",
    "#         yhat = interp(X)\n",
    "#         rmse=np.sqrt(np.mean((yhat-y)**2))\n",
    "#     # # interp = CloughTocher2DInterpolator(X, y)\n",
    "#     # yhat = interp(X)\n",
    "#     # rmse=np.sqrt(np.mean((yhat-y)**2))\n",
    "#     print(f\"the rmse of ordinairy interpolation is {rmse:.4f}\")\n",
    "\n",
    "#     # #forked from:\n",
    "#     # interp = LinearNDInterpolator(X, y)\n",
    "#     # # interp = CloughTocher2DInterpolator(X, y)\n",
    "#     # yhat = interp(X)\n",
    "#     # rmse=np.sqrt(np.mean((yhat-y)**2))\n",
    "#     # print(f\"the rmse of simple interpolation is {rmse:.4f}\")\n",
    "#     return interp\n",
    "\n",
    "#moved to lib.measure.boltzman\n",
    "# def return_top_k_trials(df,output_col,ytrgt,k=6,**kwargs):\n",
    "#     \"\"\"returns k rows that are have an absolute value of df[output_col] closest to ytrgt\n",
    "#     k=<the number of top trials to return>\n",
    "#     Example Usage:\n",
    "#     smallest_deviations=return_top_k_trials(df,output_col,ytrgt,k=k)\n",
    "#     \"\"\"\n",
    "#     unsorted_series=np.abs(df[output_col]-ytrgt)\n",
    "#     indices_of_sorted=unsorted_series.argsort()\n",
    "#     smallest_deviations=indices_of_sorted.loc[:k].values\n",
    "#     return smallest_deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.179463Z",
     "start_time": "2022-02-07T20:57:16.173262Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Recall powerlaw fits to full models\n",
    "# Fenton-Karma(PBC) \n",
    "m, Delta_m, M, Delta_M = 1.8772341309722325, 0.02498750277237229, 5.572315674840435, 0.3053120355191732\n",
    "# Luo-Rudy(PBC) \n",
    "m, Delta_m, M, Delta_M = 1.6375562704001745, 0.017190912126700632, 16.73559858353835, 0.8465090320196467\n",
    "\n",
    "# # Fenton-Karma(NCBC) \n",
    "# m, Delta_m, M, Delta_M = 1.854156794480594, 0.02503190538288011, 7.135532649256895, 0.4548432215549294\n",
    "# # Luo-Rudy(NCBC) \n",
    "# m, Delta_m, M, Delta_M = 1.6611400039209043, 0.02740424198712116, 16.75061667963681, 1.3110747548319708\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.187561Z",
     "start_time": "2022-02-07T20:57:16.180733Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_466459/857695079.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_15_all_powerlaw_fits.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_15_all/powerlaw_fits_run_15_all.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# input_cols=['r', 'D', 'varkappa']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "k=6\n",
    "#load the powerlaw data from the particle model\n",
    "input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_17_all_powerlaw_fits.csv\"\n",
    "# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_15_all_powerlaw_fits.csv\"\n",
    "# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_15_all/powerlaw_fits_run_15_all.csv\"\n",
    "df=pd.read_csv(input_fn)\n",
    "\n",
    "# input_cols=['r', 'D', 'varkappa']\n",
    "input_cols=['r','kappa', 'D', 'varkappa']\n",
    "output_col='m'\n",
    "ytrgt=m\n",
    "# output_col='M'\n",
    "# ytrgt=M\n",
    "\n",
    "#TODO: finds the values closest to ytrgt\n",
    "#define constant parameters\n",
    "reflect=0\n",
    "force_code=2\n",
    "set_second=0\n",
    "# neighbor=0\n",
    "no_attraction=0\n",
    "no_repulsion=0\n",
    "kappa=500\n",
    "L=10\n",
    "\n",
    "#query the DataFrame\n",
    "query =(df.set_second==set_second)&(df.reflect==reflect)\n",
    "query&=(df.no_repulsion==no_repulsion)&(df.no_attraction==no_attraction)\n",
    "query&=(df.neighbor==neighbor)&(df.force_code==force_code)\n",
    "# query&=df.r==r\n",
    "# query&=df.kappa==kappa\n",
    "# query&=df.D==D\n",
    "query&=df.L==L\n",
    "# query&=df.varkappa==varkappa\n",
    "# query&=df.x0==x0\n",
    "dg=df[query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.188528Z",
     "start_time": "2022-02-07T20:57:16.188518Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#compute ND interpolation fit\n",
    "interp=comp_ND_interpolation(dg,input_cols,output_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.189309Z",
     "start_time": "2022-02-07T20:57:16.189299Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#list the top k trials\n",
    "smallest_deviations=return_top_k_trials(dg,output_col,ytrgt,k=k)\n",
    "print(f\"these are the {k} trials with {output_col} closest to {ytrgt}\")\n",
    "df.loc[smallest_deviations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## TODO(later): implement genetic algorithm to find the best fit combination of r,D,a:=varkappa for a given kappa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " __Methods__ Method for genetically optimizated fit of the apparent powerlaw. \n",
    " - Step 1: choose best k=2 or 3 for a given set of sample r,D,varkappa,kappa pairs\n",
    " - Step 2: generate N=1000 random sample targets centered about the mean of ^these reproducing elite sample values.  Compute predicted output values.\n",
    "   - Hint: Results may be generated using piecewise linear interpolation for these sammples to save an exceptional amount of computational time.\n",
    " - repeat ^these last couple steps some number of times, K.\n",
    " - Perform a principle component analysis on the final iterate of ^that sample generation process.\n",
    " - select the output vector closest to the desired output value, here (m,M)\n",
    " - perform ./return_CollTimes.sh on this parameter value.  Conside improving performance with more iterates of steps 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.189913Z",
     "start_time": "2022-02-07T20:57:16.189903Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TODO: copy the cells from that genetic dev_run.ipynb \n",
    "\n",
    "#TODO: recall from up ^there that I have X,y to fit, for X.shape=(n_samples,n_dimensions:=3)\n",
    "#TODO: modify ^this to dev a genetic optimization problem \n",
    "\n",
    "# __Methods__\n",
    "# - Step 1: choose best k=2 or 3 for a given set of sample r,D,varkappa,kappa pairs\n",
    "# - Step 2: generate N=1000 random sample targets centered about the mean of ^these reproducing elite sample values.  Compute predicted output values.\n",
    "#   - Hint: Results may be generated using piecewise linear interpolation for these sammples to save an exceptional amount of computational time.\n",
    "# - repeat ^these last couple steps some number of times, K.\n",
    "# - Perform a principle component analysis on the final iterate of ^that sample generation process.\n",
    "# - select the output vector closest to the desired output value, here (m,M)\n",
    "# - perform ./return_CollTimes.sh on this parameter value.  Conside improving performance with more iterates of steps 1 and 2.\n",
    "\n",
    "#TODO: determine the elite superior\n",
    "#TODO: make a map from a number of points (K nearest neighbors, wrt m or separately M) to a correlation matrix\n",
    "#TODO: generate points about the mean randomly using ^that correlation matrix\n",
    "#TODO: test those points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## scratchwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.194519Z",
     "start_time": "2022-02-07T20:57:16.191241Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # interp.tri?\n",
    "# # Examples\n",
    "# # --------\n",
    "# # Triangulation of a set of points:\n",
    "\n",
    "# points = np.array([[0, 0], [0, 1.1], [1, 0], [1, 1]])\n",
    "# from scipy.spatial import Delaunay\n",
    "# tri = Delaunay(points)\n",
    "\n",
    "# # We can plot it:\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.triplot(points[:,0], points[:,1], tri.simplices)\n",
    "# plt.plot(points[:,0], points[:,1], 'o')\n",
    "# plt.show()\n",
    "\n",
    "# # Point indices and coordinates for the two triangles forming the triangulation:\n",
    "# print(tri.simplices)\n",
    "\n",
    "# # Note that depending on how rounding errors go, the simplices may\n",
    "# # be in a different order than above.\n",
    "# print(points[tri.simplices])\n",
    "# # Triangle 0 is the only neighbor of triangle 1, and it's opposite to vertex 1 of triangle 1:\n",
    "\n",
    "# print((tri.neighbors[1],points[tri.simplices[1,1]]))\n",
    "\n",
    "# # We can find out which triangle points are in:\n",
    "\n",
    "# p = np.array([(0.1, 0.2), (1.5, 0.5), (0.5, 1.05)])\n",
    "# print(tri.find_simplex(p))\n",
    "# # The returned integers in the array are the indices of the simplex the\n",
    "# # corresponding point is in. If -1 is returned, the point is in no simplex.\n",
    "# # Be aware that the shortcut in the following example only works corretcly\n",
    "# # for valid points as invalid points result in -1 which is itself a valid\n",
    "# # index for the last simplex in the list.\n",
    "\n",
    "# p_valids = np.array([(0.1, 0.2), (0.5, 1.05)])\n",
    "# tri.simplices[tri.find_simplex(p_valids)]\n",
    "\n",
    "# # We can also compute barycentric coordinates in triangle 1 for these points:\n",
    "\n",
    "# b = tri.transform[1,:2].dot(np.transpose(p - tri.transform[1,2]))\n",
    "# np.c_[np.transpose(b), 1 - b.sum(axis=0)]\n",
    "\n",
    "# # The coordinates for the first point are all positive, meaning it\n",
    "# # is indeed inside the triangle. The third point is on a vertex,\n",
    "# # hence its null third coordinate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# boltzmann defect weighting of the K nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- DONE: do ^this with the inverse powerlaw data (force_code==2)\n",
    "- TODO: convert to functional routine boltzmann defect weighting of the K nearest neighbors\n",
    "- TODO: move routine to lib.routines\n",
    "- TODO(later): repeat with reflect==1\n",
    "- TODO(later): do ^this with the anti-hookean data (force_code==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.205143Z",
     "start_time": "2022-02-07T20:57:16.195591Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_466459/2673722833.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_15_all_powerlaw_fits.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_15_all/powerlaw_fits_run_15_all.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# input_cols=['r', 'D', 'varkappa']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "k=6\n",
    "#load the powerlaw data from the particle model\n",
    "# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_17_all_powerlaw_fits.csv\"\n",
    "# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_15_all_powerlaw_fits.csv\"\n",
    "# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_15_all/powerlaw_fits_run_15_all.csv\"\n",
    "df=pd.read_csv(input_fn)\n",
    "\n",
    "# input_cols=['r', 'D', 'varkappa']\n",
    "input_cols=['r','kappa', 'D', 'varkappa']\n",
    "output_col='m'\n",
    "# output_col='M'\n",
    "# ytrgt=M\n",
    "\n",
    "#TODO: finds the values closest to ytrgt\n",
    "#define constant parameters\n",
    "reflect=0\n",
    "force_code=2\n",
    "set_second=0\n",
    "# neighbor=0\n",
    "no_attraction=0\n",
    "no_repulsion=0\n",
    "kappa=500\n",
    "L=10\n",
    "\n",
    "#query the DataFrame\n",
    "query =(df.set_second==set_second)&(df.reflect==reflect)\n",
    "query&=(df.no_repulsion==no_repulsion)&(df.no_attraction==no_attraction)\n",
    "query&=(df.neighbor==neighbor)&(df.force_code==force_code)\n",
    "# query&=df.r==r\n",
    "# query&=df.kappa==kappa\n",
    "# query&=df.D==D\n",
    "query&=df.L==L\n",
    "# query&=df.varkappa==varkappa\n",
    "# query&=df.x0==x0\n",
    "dg=df[query]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T03:12:24.578686Z",
     "start_time": "2021-09-03T03:12:24.561311Z"
    },
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.206098Z",
     "start_time": "2022-02-07T20:57:16.206087Z"
    },
    "hidden": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "#GOAL: dev genetic algorithm using Boltzman Defect Weighting\n",
    "#DONE: wrap ^this into a function\n",
    "#TODO: repeat ^this with M\n",
    "#TODO: return result as dict_out with mtrgt,Mtrgt,K,src,[and outputs]\n",
    "#TODO: put ^that into an output_vector, (m1,M(m1)) and for the M optimized K=5 elite members, (m(M2),M2).  Then, consider seeding the next generation with a correlation matrix times a normally distributed random variable, plus a  random linear interpolant of the fitting points for the K=5 elite of m1_values and M2_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T03:14:20.991515Z",
     "start_time": "2021-09-03T03:14:20.902567Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.206615Z",
     "start_time": "2022-02-07T20:57:16.206605Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #TODO: \n",
    "# m1_values=df.loc[smallest_deviations, output_col].values\n",
    "# # TODO: and M2_values\n",
    "\n",
    "# output_values=m1_values\n",
    "\n",
    "# #TODO: find the values closest to m\n",
    "# ytrgt=M\n",
    "# k=20\n",
    "# input_cols=['r','kappa', 'D', 'varkappa']\n",
    "# output_col='m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.207279Z",
     "start_time": "2022-02-07T20:57:16.207269Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Recall powerlaw fits to full models\n",
    "# Fenton-Karma(PBC) \n",
    "m, Delta_m, M, Delta_M = 1.8772341309722325, 0.02498750277237229, 5.572315674840435, 0.3053120355191732\n",
    "wjr={\n",
    "    'fk_pbc':{'m':m, 'Delta_m':Delta_m, 'M':M, 'Delta_M':Delta_M}\n",
    "}\n",
    "# Luo-Rudy(PBC) \n",
    "m, Delta_m, M, Delta_M = 1.6375562704001745, 0.017190912126700632, 16.73559858353835, 0.8465090320196467\n",
    "wjr['lr_pbc']={'m':m, 'Delta_m':Delta_m, 'M':M, 'Delta_M':Delta_M}\n",
    "print(*wjr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T04:53:47.110609Z",
     "start_time": "2021-09-03T04:53:47.094942Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.214196Z",
     "start_time": "2022-02-07T20:57:16.208484Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_466459/482863605.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munsorted_series\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mytrgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mindices_of_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munsorted_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msmallest_deviations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices_of_sorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#         boo=unsorted_series.index.values==unsorted_series.loc[smallest_deviations[0]].values[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#         for sd in smallest_deviations[1:]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dg' is not defined"
     ]
    }
   ],
   "source": [
    "unsorted_series=np.abs(dg[output_col]-ytrgt)\n",
    "indices_of_sorted=unsorted_series.argsort()\n",
    "smallest_deviations=indices_of_sorted.loc[:k-1].values\n",
    "#         boo=unsorted_series.index.values==unsorted_series.loc[smallest_deviations[0]].values[0]\n",
    "#         for sd in smallest_deviations[1:]:\n",
    "#             sdd=unsorted_series.iloc[sd].values[0]\n",
    "#             boo|=unsorted_series.index.values==sdd\n",
    "#     print(df.loc[smallest_deviations,cols])\n",
    "#compute the boltzmann weighted mean m\n",
    "output_disagreement_values=unsorted_series.iloc[indices_of_sorted].values[:k-1]#df.loc[boo,output_col].values\n",
    "boltzman_weighted_mean=comp_boltzman_weighted_mean(output_disagreement_values)#,**kwargs)\n",
    "boltzman_weighted_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T05:13:19.924042Z",
     "start_time": "2021-09-03T05:13:19.907584Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.215200Z",
     "start_time": "2022-02-07T20:57:16.215189Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# routine for Boltzman Defect Weighting\n",
    "# (weight_values*elite_parameter_values[:,1]**2).shape\n",
    "k=6\n",
    "input_cols=['r','kappa', 'D', 'varkappa']\n",
    "# model_name_lst=['fk_pbc','lr_pbc','fk_ncbc', 'lr_ncbc']\n",
    "output_col_lst=['m','M']\n",
    "\n",
    "dict_bwm=compute_boltzman_defect_weighted_mean_for_top_k(df=dg,k=6)\n",
    "df_bwm=pd.DataFrame(dict_bwm)\n",
    "df_bwm.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.221229Z",
     "start_time": "2022-02-07T20:57:16.216393Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_bwm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_466459/2805848121.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#print the bwm parameter value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minput_param_bwm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_bwm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fk_pbc_m'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_bwm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fk_pbc_m'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_bwm' is not defined"
     ]
    }
   ],
   "source": [
    "#print the bwm parameter value\n",
    "input_param_bwm=df_bwm.T.loc['fk_pbc_m',input_cols].values\n",
    "df_bwm.T.loc['fk_pbc_m',input_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.222123Z",
     "start_time": "2022-02-07T20:57:16.222112Z"
    },
    "hidden": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "ytrgt=m\n",
    "output_col='m'\n",
    "unsorted_series=np.abs(df[output_col]-ytrgt)\n",
    "indices_of_sorted=unsorted_series.argsort()\n",
    "input_param_values=df.loc[indices_of_sorted,input_cols].head(k).values\n",
    "# unsorted_series[indices_of_sorted.values].values\n",
    "# output_disagreement_values=unsorted_series.loc[indices_of_sorted.values].values[:k-1]\n",
    "# output_disagreement_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T05:03:52.369770Z",
     "start_time": "2021-09-03T05:03:52.336759Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.569758Z",
     "start_time": "2022-02-07T20:57:16.225454Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_param_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_466459/3437144686.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#DONE: perform PCA on the top k outputs minus the parameter mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_param_values\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_param_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_param_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_param_values' is not defined"
     ]
    }
   ],
   "source": [
    "#DONE: perform PCA on the top k outputs minus the parameter mean\n",
    "from sklearn.decomposition import PCA\n",
    "X=input_param_values-np.mean(input_param_values,axis=0)\n",
    "pca = PCA(n_components=input_param_values.shape[1])\n",
    "pca.fit(X)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.572416Z",
     "start_time": "2022-02-07T20:57:16.572406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(f\"somethings not right if the best for the fk_pbc model has zero for all fields...\")\n",
    "dict_bwm=compute_boltzman_defect_weighted_mean_for_top_k(df=dg,k=4)\n",
    "# df_bwm=pd.DataFrame(compute_boltzman_defect_weighted_mean_for_top_k(df=dg,k=2))\n",
    "df_bwm.head()\n",
    "print(df_bwm['fk_pbc_m'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.573581Z",
     "start_time": "2022-02-07T20:57:16.573563Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #compute the linear ND interpolating function mapping the parameter space to the output m space, restricting to 4 variables\n",
    "#define parameters to be varied\n",
    "# input_cols=['r','D','varkappa']#,x0\n",
    "input_cols=['r','kappa','D','varkappa']#,x0\n",
    "output_col='m'\n",
    "#inputs:dg,input_cols,output_col\n",
    "#output: fitted model\n",
    "\n",
    "Xall=dg[input_cols].values \n",
    "yall=dg[output_col].values\n",
    "X=Xall.copy()\n",
    "y=yall.copy()\n",
    "m = len(y) # number of training examples\n",
    "print(f'number of training examples is {m:d}.')\n",
    "\n",
    "interp = LinearNDInterpolator(X, y)\n",
    "# interp = CloughTocher2DInterpolator(X, y)\n",
    "yhat = interp(X)\n",
    "rmse=np.sqrt(np.mean((yhat-y)**2))\n",
    "print(f\"the rmse of simple interpolation is {rmse:.4f}\")\n",
    "\n",
    "# yhat = interp(X)\n",
    "print(f\"shape of X {X.shape} --> shape of y=yhat {yhat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.574486Z",
     "start_time": "2022-02-07T20:57:16.574470Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#DONE: compute m boltzman weighted average as m1\n",
    "#DONE: compute M boltzman weighted average as M2\n",
    "#DONE: compute interp for the full parameter space as above\n",
    "#TODO: dev compute_M(m1) via interpolation near output_cols=(r,kappa,D,varkappa) using interp\n",
    "#TODO: dev compute_m(M2) using interp\n",
    "\n",
    "#TODO: plot the linear interpolation of m,M using plt.plot()\n",
    "# print(list(zip((model_name_lst,output_col_lst,m1avg_lst,M2avg_lst))))\n",
    "\n",
    "print(dict_bwm['fk_pbc_m'])\n",
    "print(f\"\"\"the boltzman weighted mean exponent fitted to the Luo-Rudy model was\n",
    "m_lr_observed_bwm :{dict_bwm['fk_pbc_m']['m']:.5f} +- {dict_bwm['fk_pbc_m']['Delta_m']:.5f}\n",
    "m_lr_expected_wjr : {wjr['fk_pbc']['m']:.5f} +- {wjr['fk_pbc']['Delta_m']:.5f}\n",
    "\n",
    "With mean parameters\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "#TODO: compute the two points\n",
    "#TODO: interpolate as boltzman_weighted_mean\n",
    "#TODO: dev compute_boltzman_weighted_cov... Hint: check numpy.linalg.\n",
    "#TODO: using interp, generate 1000 novel offspring... and also include the original line in the coming progeny..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.575626Z",
     "start_time": "2022-02-07T20:57:16.575610Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "r=dict_bwm['fk_pbc_m']['r']\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# plot the top 1 trials for either full model\n",
    "- using a log(w) versus log(q) plot \n",
    "- with particle data scatterplotted to overlay the powerlaw fits of the full models\n",
    "- wrap ^this functionally into a function that takes an input ax,df_particle_drates and plots the scatterplot data and the fit\n",
    "- generate a run_15_top_6.pdf using bluf.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.576450Z",
     "start_time": "2022-02-07T20:57:16.576434Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_15_all.csv\"\n",
    "df_raw=pd.read_csv(input_fn)\n",
    "#derived values\n",
    "# df_raw['CollRate']=1./df_raw['CollTime']\n",
    "df_raw['A']=df_raw['L']**2\n",
    "df_raw['q']=df_raw['N']/df_raw['A'] #number of tips per square centimeter\n",
    "df_raw['w']=df_raw['CollRate']/df_raw['A'] #[mHz?]/cm^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.577698Z",
     "start_time": "2022-02-07T20:57:16.577682Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "k=0#for k in range(len(smallest_deviations_lst[0])):\n",
    "trial_index_1=smallest_deviations_lst[0][k]\n",
    "trial_index_2=smallest_deviations_lst[1][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T20:06:48.665193Z",
     "start_time": "2021-09-01T20:06:48.637356Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.578815Z",
     "start_time": "2022-02-07T20:57:16.578799Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#compute the powerlaw fitted values for the k^th best exponent (i) with and (ii) without scaling\n",
    "# FK model\n",
    "x_values=np.linspace(0.1,1,91)\n",
    "d=df.loc[trial_index_1]\n",
    "yhat1=d['M']*x_values**d['m']\n",
    "yhat1_scaled=wjr['fk_pbc']['M']*x_values**d['m']\n",
    "scale_factor1=wjr['fk_pbc']['M']/d['M']\n",
    "\n",
    "#computation of tscores\n",
    "t_m_FK=(wjr['fk_pbc']['m']-d['m'])/np.max((wjr['fk_pbc']['Delta_m'],d['Delta_m']))\n",
    "print(f\"t_m_FK={t_m_FK:.5f}\")\n",
    "\n",
    "#query the DataFrame for this d\n",
    "query =(df_raw.set_second==d['set_second'])&(df_raw.reflect==d['reflect'])\n",
    "query&=(df_raw.no_repulsion==d['no_repulsion'])&(df_raw.no_attraction==d['no_attraction'])\n",
    "query&=(df_raw.neighbor==int(d['neighbor']))&(df_raw.force_code==int(d['force_code']))\n",
    "query&=df_raw.r==d['r']\n",
    "query&=df_raw.kappa==d['kappa']\n",
    "query&=df_raw.D==d['D']\n",
    "query&=df_raw.L==d['L']\n",
    "query&=df_raw.varkappa==d['varkappa']\n",
    "query&=df_raw.x0==d['x0']\n",
    "dg=df_raw[query]\n",
    "#and extract the xy values\n",
    "x1_values=dg.q.values\n",
    "y1_values=dg.w.values\n",
    "y1_scaled_values=y1_values*scale_factor1\n",
    "\n",
    "#LR model\n",
    "d=df.loc[trial_index_2]\n",
    "yhat2=d['M']*x_values**d['m']\n",
    "yhat2_scaled=wjr['lr_pbc']['M']*x_values**d['m']\n",
    "scale_factor2=wjr['lr_pbc']['M']/d['M']\n",
    "\n",
    "#computation of tscores\n",
    "t_m_LR=(wjr['lr_pbc']['m']-d['m'])/np.max((wjr['lr_pbc']['Delta_m'],d['Delta_m']))\n",
    "print(f\"t_m_LR={t_m_LR:.5f}\")\n",
    "\n",
    "#query the DataFrame for this d\n",
    "query =(df_raw.set_second==d['set_second'])&(df_raw.reflect==d['reflect'])\n",
    "query&=(df_raw.no_repulsion==d['no_repulsion'])&(df_raw.no_attraction==d['no_attraction'])\n",
    "query&=(df_raw.neighbor==int(d['neighbor']))&(df_raw.force_code==int(d['force_code']))\n",
    "query&=df_raw.r==d['r']\n",
    "query&=df_raw.kappa==d['kappa']\n",
    "query&=df_raw.D==d['D']\n",
    "query&=df_raw.L==d['L']\n",
    "query&=df_raw.varkappa==d['varkappa']\n",
    "query&=df_raw.x0==d['x0']\n",
    "dg=df_raw[query]\n",
    "#and extract the xy values\n",
    "x2_values=dg.q.values\n",
    "y2_values=dg.w.values\n",
    "y2_scaled_values=y2_values*scale_factor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.579897Z",
     "start_time": "2022-02-07T20:57:16.579880Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "80*0.03,4*2.22 #cm^2/s attractive force magnitude\n",
    "500*0.03,250*2.22 #Hz reaction rate\n",
    "1.6*0.03,1.3*2.22 #cm^2/s diffusion coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.580889Z",
     "start_time": "2022-02-07T20:57:16.580874Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot fits for full model\n",
    "m_fk=wjr['fk_pbc']['m']\n",
    "m_lr=wjr['lr_pbc']['m']\n",
    "M_fk=wjr['fk_pbc']['M']# Hz*cm^{2(m-1)}\n",
    "M_lr=wjr['lr_pbc']['M']# Hz*cm^{2(m-1)}\n",
    "# RMSE_fk=0.1252 Hz/cm^2\n",
    "# RMSE_lr=0.0974 Hz/cm^2\n",
    "# R^2=0.997 (FK)\n",
    "# R^2=0.994 (LR)\n",
    "\n",
    "xv=np.arange(0.1,1.,.05)\n",
    "yv_fk=M_fk*(xv)**m_fk\n",
    "yv_lr=M_lr*(xv)**m_lr\n",
    "\n",
    "yscale=10**3\n",
    "fontsize=16\n",
    "# plt.xlim([0.1,1])\n",
    "# plt.ylim([1e-1,15])\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.plot(xv,yv_fk,label='FK power law fit',zorder=3,lw=4)\n",
    "plt.plot(xv,yv_lr,label='LR power law fit',zorder=3,lw=4)\n",
    "\n",
    "#plot particle model for the FK model\n",
    "plt.scatter(x1_values,y1_values,label=f'(#{k+1} exponent found for FK model)',c='C3',alpha=0.3)\n",
    "plt.plot(x_values,yhat1,label=f'powerlaw fit, particle model',c='C3',alpha=.7,zorder=3,lw=3)\n",
    "\n",
    "#plot particle model for the LR model\n",
    "plt.scatter(x2_values,y2_values,label=f'(#{k+1} exponent found for LR model)',c='C4',alpha=0.3)\n",
    "plt.plot(x_values,yhat2,label=f'powerlaw fit, particle model',c='C4',alpha=.7,zorder=3,lw=3)\n",
    "\n",
    "\n",
    "# plt.title(u'comparison to simulation\\nwith two hybrid modes',fontsize=fontsize)\n",
    "plt.xlabel(r'q (cm$^{-2}$)',fontsize=fontsize)\n",
    "plt.ylabel(r'w (Hz cm$^{-2}$)', fontsize=fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "plt.tick_params(axis='both', which='minor', labelsize=0)\n",
    "plt.legend(fontsize=fontsize-5,ncol=2,loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.581892Z",
     "start_time": "2022-02-07T20:57:16.581876Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#plot fits for full model, with time rescaling\n",
    "m_fk=wjr['fk_pbc']['m']\n",
    "m_lr=wjr['lr_pbc']['m']\n",
    "M_fk=wjr['fk_pbc']['M']# Hz*cm^{2(m-1)}\n",
    "M_lr=wjr['lr_pbc']['M']# Hz*cm^{2(m-1)}\n",
    "# RMSE_fk=0.1252 Hz/cm^2\n",
    "# RMSE_lr=0.0974 Hz/cm^2\n",
    "# R^2=0.997 (FK)\n",
    "# R^2=0.994 (LR)\n",
    "\n",
    "xv=np.arange(0.1,1.,.05)\n",
    "yv_fk=M_fk*(xv)**m_fk\n",
    "yv_lr=M_lr*(xv)**m_lr\n",
    "\n",
    "yscale=10**3\n",
    "fontsize=16\n",
    "# plt.xlim([0.1,1])\n",
    "plt.ylim([5e-2,80])\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.plot(xv,yv_fk,label='FK power law fit',zorder=3,lw=4)\n",
    "plt.plot(xv,yv_lr,label='LR power law fit',zorder=3,lw=4)\n",
    "\n",
    "#plot particle model for the FK model\n",
    "plt.scatter(x1_values,y1_scaled_values,label=f\"particle model setting A\",c='C3',alpha=0.3)\n",
    "# plt.scatter(x1_values,y1_scaled_values,label=f'(#{k+1} exponent found for FK model\\nrescaled by M_new/M_old={scale_factor1:.2f}',c='C3',alpha=0.3)\n",
    "# plt.scatter(x1_values,y1_scaled_values,label=f'(#{k+1} exponent found for FK model,\\nrescaled time)',c='C3',alpha=0.3)\n",
    "# plt.plot(x_values,yhat1_scaled,label=f'powerlaw fit, particle model,\\nrescaled by M_new/M_old={scale_factor1:.2f}',c='C3',alpha=.7,zorder=3,lw=3)\n",
    "\n",
    "#plot particle model for the LR model\n",
    "plt.scatter(x2_values,y2_scaled_values,label=f\"particle model setting B\",c='C4',alpha=0.3)\n",
    "# plt.scatter(x2_values,y2_scaled_values,label=f'(#{k+1} exponent found for LR model,\\nrescaled by M_new/M_old={scale_factor2:.2f}',c='C4',alpha=0.3)\n",
    "# plt.scatter(x2_values,y2_scaled_values,label=f'(#{k+1} exponent found for LR model,\\nrescaled time)',c='C4',alpha=0.3)\n",
    "# plt.plot(x_values,yhat2_scaled,label=f'powerlaw fit, particle model,\\nrescaled by M_new/M_old={scale_factor2:.2f}',c='C4',alpha=.7,zorder=3,lw=3)\n",
    "\n",
    "\n",
    "# plt.title(u'comparison to simulation\\nwith two hybrid modes',fontsize=fontsize)\n",
    "plt.xlabel(r'q (cm$^{-2}$)',fontsize=fontsize)\n",
    "plt.ylabel(r'w (Hz cm$^{-2}$)', fontsize=fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "plt.tick_params(axis='both', which='minor', labelsize=0)\n",
    "plt.legend(fontsize=fontsize-5,ncol=2,loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.582993Z",
     "start_time": "2022-02-07T20:57:16.582976Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d=df.loc[trial_index_1]\n",
    "print(f\"printing results for particle model fit to FK model\")\n",
    "boo=(x1_values>=0.2)&(x1_values<=1.0)\n",
    "print_fit_power_law(x1_values[boo],y1_scaled_values[boo])\n",
    "print(f\"^this particle model used parameters:\")\n",
    "print(d[input_cols])\n",
    "\n",
    "d=df.loc[trial_index_2]\n",
    "print(f\"\\nprinting results for particle model fit to LR model\")\n",
    "boo=(x2_values>=0.2)&(x2_values<=1.0)\n",
    "print_fit_power_law(x2_values[boo],y2_scaled_values[boo])\n",
    "print(f\"^this particle model used parameters:\")\n",
    "print(d[input_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.583772Z",
     "start_time": "2022-02-07T20:57:16.583757Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T01:49:49.394383Z",
     "start_time": "2021-09-02T01:49:49.366646Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# dev functionally automating level set computing on the m heatmaps of a versus r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.584918Z",
     "start_time": "2022-02-07T20:57:16.584901Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #TODO: move this to lib_care.measure\n",
    "# #TODO: These were copied to lib.measure... and lib_care.measure and care/lib.measure\n",
    "# def comp_largest_level_set(array,level,txt):\n",
    "#     #extract the contour in pixel coordinates\n",
    "#     contours=find_contours(array=array, level=level, fully_connected='low', positive_orientation='low', mode='hard_boundary')#, *, mask=None)\n",
    "#     num_contours=len(contours)\n",
    "#     assert(num_contours>0)\n",
    "#     minsize=0\n",
    "#     for contour_any in contours:\n",
    "#         if contour_any.shape[0]>minsize:\n",
    "#             minsize=contour_any.shape[0]\n",
    "#             contour=contour_any\n",
    "#     # plt.plot(contour[:,1],contour[:,0])\n",
    "\n",
    "#     #map pixel coordinates to input coordinates using bilinear interpolation\n",
    "#     #doubling kwargs width and height effectively nullifies the periodic boundary conditions used in interpolate_txt_to_contour by default\n",
    "#     width=2*array.shape[0]\n",
    "#     height=2*array.shape[1]\n",
    "#     contour_values=np.array(interpolate_txt_to_contour(contour,width,height,txt=txt))[1:]#[1:] fixes bug from periodic boundary conditions\n",
    "#     return contour_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.585855Z",
     "start_time": "2022-02-07T20:57:16.585837Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from inspect import getsource\n",
    "# print (\n",
    "#     getsource(moving_average))\n",
    "# find_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.587133Z",
     "start_time": "2022-02-07T20:57:16.587102Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def smooth_contour_xy(contour_values,navg=20,xcol=0,ycol=1):\n",
    "#     '''returns contour smoothed by a simple moving average with a moving window length of navg nodes/values.\n",
    "#     uses <function lib_care.measure.compute_forces_at_annihilation.moving_average(x, w)>, which should be moved to lib_care.measure.moving_average.py\n",
    "#     Example Usage:\n",
    "#     x_smoothed,y_smoothed=smooth_contour_xy(contour_values,w=20)\n",
    "#     '''\n",
    "#     x=contour_values[:,xcol]\n",
    "#     y=contour_values[:,ycol]\n",
    "#     x_smoothed=moving_average(x,w=navg)\n",
    "#     y_smoothed=moving_average(y,w=navg)\n",
    "#     return x_smoothed,y_smoothed\n",
    "\n",
    "# def smooth_contour(contour_values,navg=20):\n",
    "#     '''returns contour smoothed by a simple moving average with a moving window length of navg nodes/values.\n",
    "#     uses <function lib_care.measure.compute_forces_at_annihilation.moving_average(x, w)>, which should be moved to lib_care.measure.moving_average.py\n",
    "#     Example Usage:\n",
    "#     smoothed_contour_value_lst=smooth_contour(contour_values,navg=20)\n",
    "#     '''\n",
    "#     smoothed_contour_value_lst=[]\n",
    "#     for col in range(contour_values.shape[1]):\n",
    "#         x=contour_values[:,col]\n",
    "#         x_smoothed=moving_average(x,w=navg)\n",
    "#         smoothed_contour_value_lst.append(x_smoothed)\n",
    "#     return smoothed_contour_value_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.588069Z",
     "start_time": "2022-02-07T20:57:16.588053Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def comp_meshgrid_from_X(X,nsamples=1000):\n",
    "#     #define the local grid for visualization of N-dim interpolation\n",
    "#     num_cols=X.shape[1]\n",
    "#     xi=[]\n",
    "#     for i in range(num_cols):\n",
    "#         x=X[:,i]\n",
    "#         xi.append( np.linspace(np.min(x), np.max(x),nsamples) )\n",
    "#     XI_lst=np.meshgrid(*xi)\n",
    "#     return XI_lst\n",
    "\n",
    "# def comp_coordinate_values_from_X(X,nsamples=1000):\n",
    "#     XI_lst=comp_meshgrid_from_X(X,nsamples=nsamples)\n",
    "#     x1_values=XI_lst[0]\n",
    "#     x2_values=XI_lst[1]\n",
    "#     return x1_values, x2_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.588949Z",
     "start_time": "2022-02-07T20:57:16.588933Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def interp_txt_from_scatter(X,y,nsamples=1000,mode ='spline',**kwargs):\n",
    "#     '''input: X,y,nsamples=1000:\n",
    "#         - (N,2) numpy array as X, (N,1) numpy array as y\n",
    "#         - mode='spline' uses CloughTocher2DInterpolator, which recieves kwargs\n",
    "#         - mode='linear' uses LinearNDInterpolator, which recieves kwargs\n",
    "#     output: x1_values,x2_values,y_values\n",
    "    \n",
    "#     Example Usage:\n",
    "#     x1_values,x2_values,y_values=interp_txt_from_scatter(X,y)\n",
    "#     '''\n",
    "#     if mode == 'linear':\n",
    "#         interp = LinearNDInterpolator(X, y,**kwargs)\n",
    "#     elif mode == 'spline':\n",
    "#         interp = CloughTocher2DInterpolator(X, y,**kwargs)\n",
    "#     else:\n",
    "#         pass\n",
    "#         raise(f\"Warning: mode={mode} is not yet implemented!\")\n",
    "\n",
    "#     #compute the xy coordinate images\n",
    "#     x1_values, x2_values = comp_coordinate_values_from_X(X,nsamples=nsamples)\n",
    "\n",
    "#     #compute the target value images\n",
    "#     gridshape=x1_values.shape\n",
    "#     X_values =np.array(list(zip((x1_values.flatten(),x2_values.flatten()))))[:,0,:].T\n",
    "#     y_values = interp(X_values).reshape(gridshape[0],gridshape[1])\n",
    "#     return x1_values,x2_values,y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.590960Z",
     "start_time": "2022-02-07T20:57:16.590946Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def comp_longest_level_set_and_smooth(X,y,level,navg=20):\n",
    "#     '''returns the navg-moving average xy coordinates of the level-set \n",
    "#     curve where y(X)=level that has the most segments.\n",
    "#     - X is an N by 2 numpy array\n",
    "#     - y is an N by 1 numpy array\n",
    "#     Example Usage:\n",
    "#     output_col='m'; model_name='lr_pbc'\n",
    "#     level=wjr[model_name][output_col]\n",
    "#     y=df.loc[query,output_col].values\n",
    "#     smoothed_contour_values=comp_longest_level_set(X,y,level,navg=20)\n",
    "#     '''\n",
    "    \n",
    "    \n",
    "#     x1_values,x2_values,y_values=interp_txt_from_scatter(X,y)\n",
    "#     txt=np.stack((x1_values,x2_values)).T\n",
    "\n",
    "#     #TODO(later, add support for measuring M, Delta_M along the m-level set): concat txt from all output arrays of interest at once\n",
    "#     #- compute the y_values for each target output variable\n",
    "#     # - stack y_value_lst at the end as a txt\n",
    "#     #HINT: modify to use only first 2 axis XI_lst=comp_meshgrid_from_X(X) where X is N by D, for D channels you want the value for along the contour\n",
    "#     # ###### MemoryError: Unable to allocate 6.94 EiB for an array with shape (1000, 1000, 1000, 1000, 1000, 1000) and data type float64 \n",
    "#     # #interpolate any desired fields to txt\n",
    "#     # field_txt_col_lst=[x1_col,x2_col,'m','Delta_m','M','Delta_M']\n",
    "#     # X=df.loc[query,field_txt_col_lst].values\n",
    "#     # XI_lst=comp_meshgrid_from_X(X)\n",
    "#     # txt=np.stack(XI_lst).T\n",
    "\n",
    "#     #interpolate the smoothed contour values\n",
    "#     array=y_values\n",
    "#     contour_values=comp_largest_level_set(array,level,txt)\n",
    "#     x_smoothed,y_smoothed=smooth_contour_xy(contour_values,navg=navg)\n",
    "#     smoothed_contour_values=np.stack((x_smoothed,y_smoothed)).T\n",
    "#     #re: ###### MemoryError: Unable to allocate 6.94 EiB \n",
    "#     # smoothed_contour_value_lst=smooth_contour(contour_values,navg=20)\n",
    "#     return smoothed_contour_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute ar_star settings\n",
    "- to visualize level set curves set to powerlaw fits from the full models\n",
    "- TODO: move functions to lib.viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.591600Z",
     "start_time": "2022-02-07T20:57:16.591590Z"
    }
   },
   "outputs": [],
   "source": [
    "from lib.lib_care.measure.level_sets import compute_self_consistent_astar_rstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.592484Z",
     "start_time": "2022-02-07T20:57:16.592473Z"
    }
   },
   "outputs": [],
   "source": [
    "def PlotInterpolatedBackground(fig,ax,x1_values,x2_values,y_values,vmin,vmax,clabel,cmap,fontsize=16,show_cbar=True,**kwargs):\n",
    "    output_col=clabel\n",
    "    pcm=ax.pcolormesh(x1_values, x2_values, y_values, vmin=vmin, vmax=vmax, cmap=cmap,**kwargs)\n",
    "    if use_cbar:\n",
    "        cbar=fig.colorbar(pcm, ax=ax, shrink=0.6,label=output_col)#, location='top'\n",
    "        # fig.colorbar(pcm, ax=[axs[0, col]], location='top', shrink=0.6)\n",
    "        #     cbar=fig.colorbar(pcm, ax=axs[:, col],shrink=0.6)#,label=output_col)\n",
    "        cbar.ax.tick_params(labelsize=fontsize)\n",
    "        cbar.set_label(output_col, fontsize=fontsize)\n",
    "    return True\n",
    "\n",
    "def FormatAxes(ax,x1lim,x2lim,x1label,x2label,title,fontsize=16,use_loglog=False,**kwargs):        \n",
    "    ax.set_xlim(x1lim)\n",
    "    ax.set_ylim(x2lim)\n",
    "    ax.set_title(title,fontsize=fontsize)\n",
    "    format_plot(ax, x1label, x2label, fontsize=fontsize, use_loglog=use_loglog,**kwargs)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.593200Z",
     "start_time": "2022-02-07T20:57:16.593190Z"
    }
   },
   "outputs": [],
   "source": [
    "# Recall powerlaw fits to full models\n",
    "wjr=recall_powerlaw_fits_to_full_models()\n",
    "print(*wjr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.594120Z",
     "start_time": "2022-02-07T20:57:16.594108Z"
    }
   },
   "outputs": [],
   "source": [
    "#load the map between input parameters and emergent observables\n",
    "input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_19_all_powerlaw_fits.csv\"\n",
    "# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_17_all_powerlaw_fits.csv\"\n",
    "# input_fn=f\"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_15_all_powerlaw_fits.csv\"\n",
    "df=pd.read_csv(input_fn)\n",
    "\n",
    "#define constant parameters\n",
    "neighbor=1\n",
    "# neighbor=0\n",
    "reflect=0\n",
    "force_code=2\n",
    "set_second=0\n",
    "no_attraction=0\n",
    "no_repulsion=0\n",
    "L=10\n",
    "\n",
    "#query the DataFrame\n",
    "query =(df.set_second==set_second)&(df.reflect==reflect)\n",
    "query&=(df.no_repulsion==no_repulsion)&(df.no_attraction==no_attraction)\n",
    "query&=(df.neighbor==neighbor)&(df.force_code==force_code)\n",
    "# query&=df.r==r\n",
    "# query&=df.kappa==kappa\n",
    "# query&=df.D==D\n",
    "query&=df.L==L\n",
    "# query&=df.varkappa==varkappa\n",
    "# query&=df.x0==x0\n",
    "query_template=query.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.594807Z",
     "start_time": "2022-02-07T20:57:16.594798Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.595731Z",
     "start_time": "2022-02-07T20:57:16.595720Z"
    }
   },
   "outputs": [],
   "source": [
    "#compute the contour values for fk_pbc and lr_pbc and record the intersections in df_star\n",
    "x1_col='r'\n",
    "x2_col='varkappa'\n",
    "nsamples=1000\n",
    "navg=50\n",
    "mode='spline'#'linear'\n",
    "printing=False\n",
    "# D=2\n",
    "# D_lst=[2,0.7,14]\n",
    "D_lst=sorted(set(df.D.values))[::-1]\n",
    "print(f\"D_lst={D_lst}\")\n",
    "kappa_lst=sorted(set(df.kappa.values))[::-1]\n",
    "print(f\"iterating over kappa_lst={kappa_lst} and the PBC full model results...\")\n",
    "dict_out_lst=[]\n",
    "#FK model\n",
    "model_name='fk_pbc'\n",
    "for D in D_lst:\n",
    "    for kappa in kappa_lst:\n",
    "        query = (df['D']==D)\n",
    "        query&= (df['kappa']==kappa)\n",
    "        query&= query_template\n",
    "        X=df.loc[query,[x1_col,x2_col]].values\n",
    "\n",
    "        #computation of level set curves set to powerlaw fits from the full models\n",
    "        if printing:\n",
    "            print(f\"for the {model_name} model, when kappa={kappa:.0f} Hz and D={D:.2f} cm^2/s...\")\n",
    "        output_col='m'\n",
    "        m=float(wjr[model_name][output_col])\n",
    "        y=df.loc[query,output_col].values\n",
    "        try:\n",
    "            contour_m_values=comp_longest_level_set_and_smooth(X,y,level=m,navg=navg)\n",
    "        except AssertionError as e:#assert(num_contours>0)\n",
    "            contour_m_values=None\n",
    "        output_col='M'\n",
    "        M=float(wjr[model_name][output_col])\n",
    "        y=df.loc[query,output_col].values\n",
    "        try:\n",
    "            contour_M_values=comp_longest_level_set_and_smooth(X,y,level=M,navg=navg)\n",
    "        except AssertionError as e:#assert(num_contours>0)\n",
    "            contour_M_values=None\n",
    "        \n",
    "        if (contour_m_values is not None) and (contour_M_values is not None):\n",
    "            contour_m_values_LR=contour_m_values.copy()\n",
    "            contour_M_values_LR=contour_M_values.copy()\n",
    "\n",
    "            try:\n",
    "                #compute the self-consistent intersection points\n",
    "                rstar,astar=compute_self_consistent_astar_rstar(contour_m_values,contour_M_values)\n",
    "            except AssertionError as e:#assert (x1star_values.shape[0]>0)\n",
    "                rstar=np.nan\n",
    "                astar=np.nan\n",
    "        else:\n",
    "            rstar=np.nan\n",
    "            astar=np.nan\n",
    "\n",
    "        #collect results into a dictionary\n",
    "        dict_out={\n",
    "            'model_name':model_name,\n",
    "            'rstar':rstar,\n",
    "            'astar':astar,\n",
    "            'kappa':kappa,\n",
    "            'D':D,\n",
    "            'm':m,\n",
    "            'M':M\n",
    "        }\n",
    "        # append that dict to list\n",
    "        dict_out_lst.append(dict_out)\n",
    "#LR model\n",
    "model_name='lr_pbc'\n",
    "for D in D_lst:\n",
    "    for kappa in kappa_lst:\n",
    "        query = (df['D']==D)\n",
    "        query&= (df['kappa']==kappa)\n",
    "        query&= query_template\n",
    "        X=df.loc[query,[x1_col,x2_col]].values\n",
    "\n",
    "        if printing:\n",
    "            print(f\"for the {model_name} model, when kappa={kappa:.0f} Hz and D={D:.2f} cm^2/s...\")\n",
    "\n",
    "        output_col='m'\n",
    "        m=float(wjr[model_name][output_col])\n",
    "        y=df.loc[query,output_col].values\n",
    "        try:\n",
    "            contour_m_values=comp_longest_level_set_and_smooth(X,y,level=m,navg=navg)\n",
    "        except AssertionError as e:#assert(num_contours>0)\n",
    "            contour_m_values=None\n",
    "        output_col='M'\n",
    "        M=float(wjr[model_name][output_col])\n",
    "        y=df.loc[query,output_col].values\n",
    "        try:\n",
    "            contour_M_values=comp_longest_level_set_and_smooth(X,y,level=M,navg=navg)\n",
    "        except AssertionError as e:#assert(num_contours>0)\n",
    "            contour_M_values=None\n",
    "        \n",
    "        if (contour_m_values is not None) and (contour_M_values is not None):\n",
    "            contour_m_values_LR=contour_m_values.copy()\n",
    "            contour_M_values_LR=contour_M_values.copy()\n",
    "\n",
    "            try:\n",
    "                #compute the self-consistent intersection points\n",
    "                rstar,astar=compute_self_consistent_astar_rstar(contour_m_values,contour_M_values)\n",
    "            except AssertionError as e:#assert (x1star_values.shape[0]>0)\n",
    "                rstar=np.nan\n",
    "                astar=np.nan\n",
    "        else:\n",
    "            rstar=np.nan\n",
    "            astar=np.nan\n",
    "        #collect results into a dictionary\n",
    "        dict_out={\n",
    "            'model_name':model_name,\n",
    "            'rstar':rstar,\n",
    "            'astar':astar,\n",
    "            'kappa':kappa,\n",
    "            'D':D,\n",
    "            'm':m,\n",
    "            'M':M\n",
    "        }\n",
    "        # append that dict to list\n",
    "        dict_out_lst.append(dict_out)\n",
    "\n",
    "df_star=pd.DataFrame(dict_out_lst)\n",
    "print(df_star.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.596413Z",
     "start_time": "2022-02-07T20:57:16.596402Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_star[df_star=='fk_pbc']\n",
    "df_star.dropna()j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.597167Z",
     "start_time": "2022-02-07T20:57:16.597157Z"
    }
   },
   "outputs": [],
   "source": [
    "df_star.dropna(inplace=True)\n",
    "df_star[df_star.D==0.3].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.598023Z",
     "start_time": "2022-02-07T20:57:16.598012Z"
    }
   },
   "outputs": [],
   "source": [
    "df_star[df_star.D==0.7].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.598778Z",
     "start_time": "2022-02-07T20:57:16.598767Z"
    }
   },
   "outputs": [],
   "source": [
    "#DONE: iterate over models and kappas of interest\n",
    "#DONE: format dict_out_lst into df_star\n",
    "#TODO: save df_star to .csv\n",
    "\n",
    "printing=True\n",
    "save_folder=None\n",
    "save_fn=None\n",
    "saving=True\n",
    "# if printing:\n",
    "#     print(f\"parsing absolute directory of input_fn={input_fn}...\")\n",
    "input_folder=os.path.dirname(input_fn)\n",
    "trial_folder_name=os.path.dirname(input_folder)\n",
    "if save_folder is None:\n",
    "    save_folder=input_folder\n",
    "if save_fn is None:\n",
    "    save_fn = os.path.basename(input_fn).replace('_all_powerlaw_fits.csv','_ar_star.csv')\n",
    "\n",
    "if saving:\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.mkdir(save_folder)\n",
    "    os.chdir(save_folder)\n",
    "    df_star.to_csv(save_fn,index=False)\n",
    "    save_fn=os.path.abspath(save_fn)\n",
    "    if printing:\n",
    "        print(f\"self-consistent intersection parameters were successfully saved to \\n{save_fn}\")\n",
    "#     intersection_dir=save_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.599496Z",
     "start_time": "2022-02-07T20:57:16.599486Z"
    }
   },
   "outputs": [],
   "source": [
    "# play with ar_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.600421Z",
     "start_time": "2022-02-07T20:57:16.600407Z"
    }
   },
   "outputs": [],
   "source": [
    "df_star.iloc[-1].copy().astar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.601293Z",
     "start_time": "2022-02-07T20:57:16.601279Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: extract from single lines/rows print(df_star) to format a string of the form\n",
    "# dff=df_star.iloc[-1].copy()\n",
    "c_folder=f\"{nb_dir}/../c/attractive\"\n",
    "os.chdir(c_folder)\n",
    "for i in range(1,5):\n",
    "    sim_str=f\"date; ./xrun.sh {df_star.iloc[-i].rstar:.6f} {df_star.iloc[-i].D:.6f} 10 {df_star.iloc[-i].kappa} {df_star.iloc[-i].astar:.6f} 0 1e-5 1e-5 100 1500 1234 0 0 0 0 1 2 > Log/out.{df_star.iloc[-i].name}\"\n",
    "    print (sim_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.601962Z",
     "start_time": "2022-02-07T20:57:16.601951Z"
    }
   },
   "outputs": [],
   "source": [
    "# intersection_dir='/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_15_ar_star.csv'\n",
    "intersection_dir='/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_17_ar_star.csv'\n",
    "intersection_dir_neighbors='/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_19_ar_star.csv'\n",
    "df_star=pd.read_csv(intersection_dir)\n",
    "df_star.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Example computation of an rstar and astar pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T23:43:07.581221Z",
     "start_time": "2021-09-14T23:43:07.558273Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.602641Z",
     "start_time": "2022-02-07T20:57:16.602631Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compute_powerlaw_contours(df,D,kappa,query_template,x1_col='r',x2_col='varkappa',model_name='fk_pbc',\n",
    "                              navg=5,#50,\n",
    "                              **kwargs):\n",
    "    query = (df['D']==D)\n",
    "    query&= (df['kappa']==kappa)\n",
    "    query&= query_template\n",
    "    X=df.loc[query,[x1_col,x2_col]].values\n",
    "\n",
    "\n",
    "    output_col='m'\n",
    "    level=wjr[model_name][output_col]\n",
    "    y=df.loc[query,output_col].values\n",
    "    contour_m_values=comp_longest_level_set_and_smooth(X,y,level,navg=navg)\n",
    "\n",
    "    output_col='M'\n",
    "    level=wjr[model_name][output_col]\n",
    "    y=df.loc[query,output_col].values\n",
    "    contour_M_values=comp_longest_level_set_and_smooth(X,y,level,navg=navg)\n",
    "    return contour_m_values,contour_M_values\n",
    "\n",
    "#TODO: compute the contours for the full models\n",
    "#FK model\n",
    "D=0.7\n",
    "# D=2\n",
    "# kappa=400\n",
    "kappa=250\n",
    "# kappa=500\n",
    "contour_m_values_FK,contour_M_values_FK=compute_powerlaw_contours(df,D,kappa,query_template,x1_col='r',x2_col='varkappa',model_name='fk_pbc',\n",
    "                              navg=50)\n",
    "contour_m_values_LR,contour_M_values_LR=compute_powerlaw_contours(df,D,kappa,query_template,x1_col='r',x2_col='varkappa',model_name='lr_pbc',\n",
    "                              navg=50)\n",
    "#     contour_m_values_FK=contour_m_values.copy()\n",
    "#     contour_M_values_FK=contour_M_values.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.603544Z",
     "start_time": "2022-02-07T20:57:16.603533Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#visualize the level sets\n",
    "#compute the data for background image \n",
    "query = (df['D']==D)\n",
    "query&= (df['kappa']==kappa)\n",
    "query&= query_template\n",
    "\n",
    "#TODO: make plotting the background colored image functional\n",
    "#visualize a versus r\n",
    "x1lim=[0.05,0.5]\n",
    "x2lim=[1,50]\n",
    "# x2lim=[0,50]\n",
    "fontsize=16\n",
    "x1label=r'$r$ (cm)'\n",
    "x2label=r'$a$ (cm$^2$/s)'\n",
    "\n",
    "title_foo=lambda kappa,D:r'$\\kappa$'+f' = {kappa:.0f} Hz, D = {D:.1f} '+r'cm$^2$/s'+f'\\n'\n",
    "title=title_foo(kappa,D)\n",
    "lw=3\n",
    "alpha=0.7\n",
    "cmap = 'gray'#'bone'  #'RdBu_r'#'Greys'# \n",
    "use_cbar=True\n",
    "show_cbar =True\n",
    "use_loglog=True\n",
    "\n",
    "kwargs={}\n",
    "\n",
    "figsize=(11,4.5)#(6,4.5)#(16,6)#(16,14)\n",
    "fig,axs=plt.subplots(ncols=2, figsize=figsize)\n",
    "\n",
    "#DONE: plot fig. A contours for m\n",
    "ax=axs[0]\n",
    "output_col='m'\n",
    "vmin=1\n",
    "vmax=3\n",
    "X=df.loc[query,['r','varkappa']].values\n",
    "y=df.loc[query,output_col].values\n",
    "x1_values,x2_values,y_values=interp_txt_from_scatter(X,y,nsamples=1000)\n",
    "# clabel=output_col\n",
    "clabel=r'$\\nu$'\n",
    "\n",
    "PlotInterpolatedBackground(fig,ax,x1_values,x2_values,y_values,vmin,vmax,clabel,cmap,fontsize=fontsize,show_cbar=show_cbar,**kwargs)\n",
    "FormatAxes(ax,x1lim=x1lim,x2lim=x2lim,x1label=x1label,x2label=x2label,title=title,fontsize=fontsize,use_loglog=use_loglog,**kwargs)      \n",
    "\n",
    "#DONE: plot the level sets and color them for the full models\n",
    "ax.plot(contour_m_values_FK[:,0],contour_m_values_FK[:,1],'-',lw=lw,alpha=alpha,c='C0',**kwargs)\n",
    "ax.plot(contour_m_values_LR[:,0],contour_m_values_LR[:,1],'-',lw=lw,alpha=alpha,c='C1',**kwargs)\n",
    "\n",
    "#DONE: plot fig. B contours for M\n",
    "ax=axs[1]\n",
    "output_col='M'\n",
    "vmin=0\n",
    "vmax=30\n",
    "X=df.loc[query,['r','varkappa']].values\n",
    "y=df.loc[query,output_col].values\n",
    "x1_values,x2_values,y_values=interp_txt_from_scatter(X,y,nsamples=1000)\n",
    "clabel=output_col\n",
    "\n",
    "PlotInterpolatedBackground(fig,ax,x1_values,x2_values,y_values,vmin,vmax,clabel,cmap,fontsize=fontsize,show_cbar=show_cbar,**kwargs)\n",
    "FormatAxes(ax,x1lim=x1lim,x2lim=x2lim,x1label=x1label,x2label=x2label,title=title,fontsize=fontsize,use_loglog=use_loglog,**kwargs)      \n",
    "\n",
    "#DONE: plot the level sets and color them for the full models\n",
    "ax.plot(contour_M_values_FK[:,0],contour_M_values_FK[:,1],'--',lw=lw,alpha=alpha,c='C0',**kwargs)\n",
    "ax.plot(contour_M_values_LR[:,0],contour_M_values_LR[:,1],'--',lw=lw,alpha=alpha,c='C1',**kwargs)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.604185Z",
     "start_time": "2022-02-07T20:57:16.604174Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#compute intersection points\n",
    "rstar_FK,astar_FK=compute_self_consistent_astar_rstar(contour_m_values_FK,contour_M_values_FK)\n",
    "rstar_LR,astar_LR=compute_self_consistent_astar_rstar(contour_m_values_LR,contour_M_values_LR)\n",
    "# use_loglog=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.604889Z",
     "start_time": "2022-02-07T20:57:16.604877Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#plot fig. C\n",
    "marker = '*'#'s'\n",
    "marker_size=400\n",
    "alpha=0.7\n",
    "figsize=(5,4.5)#(16,6)#(16,14)\n",
    "fig,ax=plt.subplots(ncols=1, figsize=figsize)\n",
    "\n",
    "#visualize the smoothed contour values and verify that they are reasonable\n",
    "ax.plot(contour_m_values_FK[:,0],contour_m_values_FK[:,1],'-',lw=lw,c='C0')#,**kwargs)\n",
    "ax.plot(contour_M_values_FK[:,0],contour_M_values_FK[:,1],'--',lw=lw,c='C0')#,**kwargs)\n",
    "ax.plot(contour_m_values_LR[:,0],contour_m_values_LR[:,1],'-',lw=lw,c='C1')#,**kwargs)\n",
    "ax.plot(contour_M_values_LR[:,0],contour_M_values_LR[:,1],'--',lw=lw,c='C1')#,**kwargs)\n",
    "\n",
    "\n",
    "#plot the intersection point\n",
    "plt.scatter(x = [rstar_FK,rstar_LR], y = [astar_FK,astar_LR], c='k', s=marker_size,zorder=3, marker = marker,alpha=alpha)#, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "\n",
    "#scatter plot the intersection points \n",
    "FormatAxes(ax,x1lim=x1lim,x2lim=x2lim,x1label=x1label,x2label=x2label,title=title,fontsize=fontsize,use_loglog=use_loglog,**kwargs)      \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.605574Z",
     "start_time": "2022-02-07T20:57:16.605563Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # #automatically assign axis limits to show the smallest cover\n",
    "# # lims=df_star.describe().T[['min','max']]\n",
    "# # xlim=lims.loc['kappa'].values\n",
    "# # rlim=lims.loc['rstar'].values\n",
    "# # alim=lims.loc['astar'].values\n",
    "# # D=lims.loc['D'].values[-1];print(f\"max(D)={D} cm^2/s\")\n",
    "# #custom axis limits\n",
    "# xlim=[200,600]\n",
    "# rlim=[0.05,0.2]\n",
    "# alim=[1.5,15]\n",
    "# D=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.606175Z",
     "start_time": "2022-02-07T20:57:16.606165Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#TODO: plot df_star versus kappa\n",
    "#plot fig. D,E\n",
    "D=2\n",
    "fontsize=16\n",
    "use_loglog=False\n",
    "\n",
    "#custom axis limits\n",
    "xlim=[200,550]\n",
    "rlim=[0.01,0.25]\n",
    "alim=[0,15]\n",
    "#axis labels\n",
    "xlabel=r'$\\kappa$ (Hz)'\n",
    "rlabel=r'$r^*$ (cm)'\n",
    "alabel=r'$a^*$ (cm$^2$/s)'\n",
    "title=''\n",
    "marker = '*'#'s'\n",
    "marker_size=400\n",
    "alpha=0.7\n",
    "figsize=(6,5)#(16,6)#(16,14)\n",
    "fig,axs=plt.subplots(nrows=2, figsize=figsize)\n",
    "#visualize the smoothed contour values and verify that they are reasonable\n",
    "\n",
    "#FK model\n",
    "c='C0'\n",
    "query =df_star['model_name']=='fk_pbc'\n",
    "query&=df_star['D']==D\n",
    "dff=df_star[query]\n",
    "a_values=dff['astar'].values\n",
    "r_values=dff['rstar'].values\n",
    "kappa_values=dff['kappa'].values\n",
    "#plot\n",
    "ax=axs[0]\n",
    "ax.plot(kappa_values,a_values,'-',lw=lw,c=c)#,**kwargs)\n",
    "ax.scatter(x = kappa_values,y=a_values, c='k', s=marker_size,zorder=3, marker = marker,alpha=alpha)#, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "ax=axs[1]\n",
    "ax.plot(kappa_values,r_values,'-',lw=lw,c=c)#,**kwargs)\n",
    "ax.scatter(x = kappa_values,y=r_values, c='k', s=marker_size,zorder=3, marker = marker,alpha=alpha)#, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "\n",
    "#LR model\n",
    "c='C1'\n",
    "query =df_star['model_name']=='lr_pbc'\n",
    "query&=df_star['D']==D\n",
    "dff=df_star[query]\n",
    "a_values=dff['astar'].values\n",
    "r_values=dff['rstar'].values\n",
    "kappa_values=dff['kappa'].values\n",
    "#plot\n",
    "ax=axs[0]\n",
    "ax.plot(kappa_values,a_values,'-',lw=lw,c=c)#,**kwargs)\n",
    "ax.scatter(x = kappa_values,y=a_values, c='k', s=marker_size,zorder=3, marker = marker,alpha=alpha)#, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "ax=axs[1]\n",
    "ax.plot(kappa_values,r_values,'-',lw=lw,c=c)#,**kwargs)\n",
    "ax.scatter(x = kappa_values,y=r_values, c='k', s=marker_size,zorder=3, marker = marker,alpha=alpha)#, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "\n",
    "# format the plots\n",
    "FormatAxes(axs[0],x1lim=xlim,x2lim=alim,x1label=xlabel,x2label=alabel,title=title,fontsize=fontsize,use_loglog=use_loglog,**kwargs)      \n",
    "FormatAxes(axs[1],x1lim=xlim,x2lim=rlim,x1label=xlabel,x2label=rlabel,title=title,fontsize=fontsize,use_loglog=use_loglog,**kwargs)      \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.607010Z",
     "start_time": "2022-02-07T20:57:16.606998Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#DONE: repeat for other full model\n",
    "#DONE: plot the 2 curves\n",
    "#DONE: plot the intersection point\n",
    "#DONE: make a reasonable figure\n",
    "#DONE: automate some reasonable plotting\n",
    "#DONE: repeat for other kappa\n",
    "#DONE: plot rstar,astar versus kappa\n",
    "#DONE: repeat for FK\n",
    "#TODO: finish this multi-paneled figure!!!!!!!!!!!!!!!\n",
    "#TODO: make a nice paneled figure crystalizing all these results!\n",
    "#TODO: share!\n",
    "#TODO(later?): do these results change when reflect==1?\n",
    "#TODO: consider starting a new run 16 testing a few more kappa values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.607833Z",
     "start_time": "2022-02-07T20:57:16.607822Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#DONE: crystalize ^this into a function that takes x1_values,x2_values,y_values, and level, and returns the contour xy values\n",
    "#TODO: get the orange contour for M\n",
    "#TODO: compute the intersection point where m and M self consistently describe this model as r*,a*, rstar, astar\n",
    "# rstar, astar=??\n",
    "#TODO: repeat at another kappa\n",
    "#TODO: plot kappa versus r*,a*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.608856Z",
     "start_time": "2022-02-07T20:57:16.608844Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# single_panel ploting #DONE: plot fig. B contours for M\n",
    "# output_col='M'\n",
    "# vmin=0\n",
    "# vmax=30\n",
    "\n",
    "## output_col='m'\n",
    "## vmin=1\n",
    "## vmax=3\n",
    "\n",
    "# #compute the data for background image \n",
    "# query = (df['D']==D)\n",
    "# query&= (df['kappa']==kappa)\n",
    "# query&= query_template\n",
    "# X=df.loc[query,['r','varkappa']].values\n",
    "# y=df.loc[query,output_col].values\n",
    "# x1_values,x2_values,y_values=interp_txt_from_scatter(X,y,nsamples=1000)\n",
    "\n",
    "# #TODO: make plotting the background colored image functional\n",
    "# #visualize a versus r\n",
    "# x1lim=[0.05,0.5]\n",
    "# x2lim=[1,50]\n",
    "# # x2lim=[0,50]\n",
    "# fontsize=16\n",
    "# x1label=r'$r$ (cm)'\n",
    "# x2label=r'$a$ (cm$^2$/s)'\n",
    "# # #columnal kwargs\n",
    "# # vmin_lst=[1,1]\n",
    "# # vmax_lst=[3,3]\n",
    "# # vmin_lst=[1,0]\n",
    "# # vmax_lst=[3,20]\n",
    "# # output_col_lst=['m','m']\n",
    "# # output_col_lst=['m','M']\n",
    "# #kwargs by row\n",
    "# # r_lst=[0.1,0.2]\n",
    "# kappa_lst=[250,500]\n",
    "\n",
    "# title_foo=lambda kappa:f'kappa = {kappa:.0f} Hz\\n'\n",
    "# title=title_foo(kappa)\n",
    "# clabel=output_col\n",
    "# lw=3\n",
    "# alpha=0.7\n",
    "# cmap = 'bone'  #'gray'#'RdBu_r'#'Greys'# \n",
    "# cmap = 'gray'#'bone'  #'RdBu_r'#'Greys'# \n",
    "\n",
    "# use_cbar=True\n",
    "# use_loglog=False\n",
    "\n",
    "# kwargs={}\n",
    "\n",
    "# figsize=(6,4.5)#(16,6)#(16,14)\n",
    "# fig,ax=plt.subplots(ncols=1, figsize=figsize)\n",
    "# # fig,axs=plt.subplots(ncols=2, figsize=figsize)\n",
    "# # fig, axs = plt.subplots(2, len(kappa_lst), figsize=(16,14))\n",
    "\n",
    "# PlotInterpolatedBackground(fig,ax,x1_values,x2_values,y_values,vmin,vmax,clabel,cmap,fontsize=fontsize,show_cbar=True,**kwargs)\n",
    "# FormatAxes(ax,x1lim=x1lim,x2lim=x2lim,x1label=x1label,x2label=x2label,title=title,fontsize=fontsize,use_loglog=True,**kwargs)      \n",
    "\n",
    "# #DONE: plot the level sets and color them for the full models\n",
    "# plt.plot(contour_M_values_FK[:,0],contour_M_values_FK[:,1],'--',lw=lw,alpha=alpha,c='C0',**kwargs)\n",
    "# plt.plot(contour_M_values_LR[:,0],contour_M_values_LR[:,1],'--',lw=lw,alpha=alpha,c='C1',**kwargs)\n",
    "\n",
    "# #TODO(later): compute and scatter plot the intersection points \n",
    "# #HINT rstar,astar=compute_self_consistent_astar_rstar(contour_m_values,contour_M_values)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.609411Z",
     "start_time": "2022-02-07T20:57:16.609400Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#TODO: finish this multi-paneled figure!!!!!!!!!!!!!!!\n",
    "#TODO(later): automate generating the .csv of all the powerlaw fits... also, change the output location to somewhere central.  record src in some .json file\n",
    "#TODO: dev function that repeatably generates ^this multi-paneled-figure into a fig_X.pdf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.610332Z",
     "start_time": "2022-02-07T20:57:16.610321Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TODO: print the Rsq of some of the D=0.3 astar values... they're good.that's a good (Rsq>0.98) check THUMBS UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.610859Z",
     "start_time": "2022-02-07T20:57:16.610847Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_star[df_star.D==0.3].head(10)\n",
    "df[df.D==0.3].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-15T00:24:52.612551Z",
     "start_time": "2021-09-15T00:24:52.585289Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# (optional) compute boltzmann weighted averages, where the weights are the mean squared error with respect to the smallest of the full models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.611664Z",
     "start_time": "2022-02-07T20:57:16.611654Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# intersection_dir='/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_15_ar_star.csv'\n",
    "intersection_dir='/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_17_ar_star.csv'\n",
    "df_star=pd.read_csv(intersection_dir)\n",
    "df_star.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.612391Z",
     "start_time": "2022-02-07T20:57:16.612381Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_bwm=compute_boltzman_defect_weighted_mean_for_top_k(df=dg,k=6)\n",
    "# dict_bwm=compute_boltzman_defect_weighted_mean_for_top_k(df=dg,k=6)\n",
    "df_bwm=pd.DataFrame(dict_bwm)\n",
    "df_bwm.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.613257Z",
     "start_time": "2022-02-07T20:57:16.613246Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#     return dict_bwm\n",
    "# from inspect import getsource\n",
    "# print  (   getsource(compute_boltzman_defect_weighted_mean_for_top_k\n",
    "#                     ))\n",
    "# def compute_boltzman_defect_weighted_mean_for_top_k(df,input_cols=['r','kappa', 'D', 'varkappa'],output_col_lst=['m','M'],model_name_lst=None,k=6,printing=False,**kwargs):\n",
    "#TODO: convert compute_boltzman_defect_weighted_mean_for_top_k to compute_boltzman_defect_weighted_mean_for_msemin no.... minmse roflcopter hahalolz\n",
    "def compute_boltzman_defect_weighted_mean_et_alii(df,num_to_include,**kwargs):\n",
    "    k=num_to_include\n",
    "    '''df=df_input[query] is a pandas.DataFrame instance assumed to have a unique trial\n",
    "    for any unique combination of fields indicated by input_col\n",
    "    #TODO: dev compute pca / correlation matrix about the mean\n",
    "    #TDOO: use ^this correlation matrix to inspire random sampling clouds between the bwm of the top k trials for (i) m and (ii) M.\n",
    "\n",
    "    Example Usage:\n",
    "    df_bwm=pd.DataFrame(compute_boltzman_defect_weighted_mean_for_top_k(df=dg))\n",
    "    df_bwm.head()\n",
    "    '''\n",
    "    input_cols=['r', 'kappa', 'D', 'varkappa']\n",
    "    output_col_lst=['m', 'M']\n",
    "    model_name_lst=None\n",
    "    df=df.reindex().copy()\n",
    "    cols=list(input_cols)\n",
    "    cols.extend(output_col_lst)\n",
    "\n",
    "    wjr=recall_powerlaw_fits_to_full_models()\n",
    "    if printing:\n",
    "        print(f\"recalled from lib the powerlaw fits for full models:\")\n",
    "        print(*wjr)\n",
    "\n",
    "    if model_name_lst is None:\n",
    "        model_name_lst=list(wjr.keys())\n",
    "\n",
    "    m1avg_lst=[]\n",
    "    M2avg_lst=[]\n",
    "    dict_bwm={} #dictiionary of boltzmann weighted mean values\n",
    "    dict_pca={}\n",
    "    smallest_deviations_lst=[]\n",
    "    model_name_lst=['fk_pbc','lr_pbc']\n",
    "    #for 2-dimensional target space, such as m,M\n",
    "    for model_name in model_name_lst:\n",
    "        Ytrgt=(wjr[model_name][output_col_lst[0]],wjr[model_name][output_col_lst[1]])\n",
    "        #for m\n",
    "        ytrgt=Ytrgt[0]\n",
    "        output_col=output_col_lst[0]\n",
    "#         print(f\"\\nprinting the {k} indices closest to {output_col}={ytrgt} using Ytrgt={Ytrgt}\")\n",
    "        unsorted_series=np.abs(df[output_col]-ytrgt)\n",
    "        indices_of_sorted=unsorted_series.argsort()\n",
    "        smallest_deviations=indices_of_sorted.loc[:k-1].values\n",
    "#         boo=unsorted_series.index.values==unsorted_series.loc[smallest_deviations[0]].values[0]\n",
    "#         for sd in smallest_deviations[1:]:\n",
    "#             sdd=unsorted_series.iloc[sd].values[0]\n",
    "#             boo|=unsorted_series.index.values==sdd\n",
    "    #     print(df.loc[smallest_deviations,cols])\n",
    "        #compute the boltzmann weighted mean m\n",
    "        output_disagreement_values=unsorted_series.iloc[indices_of_sorted].values[:k-1]#df.loc[boo,output_col].values\n",
    "        boltzman_weighted_mean=comp_boltzman_weighted_mean(output_disagreement_values,**kwargs)\n",
    "    #     print(f\"the boltzman_weighted_mean for the K={k} elite members was {boltzman_weighted_mean}\")\n",
    "        M2avg_lst.append(boltzman_weighted_mean)\n",
    "\n",
    "        #compute the boltzmann weighted average w.r.t. m\n",
    "        weight_values=comp_boltzman_weighted_weights(output_disagreement_values,**kwargs)\n",
    "#         elite_parameter_values=df.loc[boo].values#,cols]\n",
    "        elite_parameter_values=df.iloc[indices_of_sorted].values[:k-1]\n",
    "        dict_out=dict(zip(list(df.columns),np.sum(weight_values*elite_parameter_values.T,axis=1)))\n",
    "        dict_out['top_trial_index']=int(smallest_deviations[0])\n",
    "        dict_bwm[model_name+f'_{output_col}']=dict_out\n",
    "        if printing:\n",
    "            print(f\"the boltzman_weighted mean parameter for the K={k} elite members was {dict_out}\")\n",
    "\n",
    "        Xcentered_values=output_disagreement_values-boltzman_weighted_mean\n",
    "#         Xsvd_values=np.linalg.svd(Xcentered_values)\n",
    "        corrcoeff_values=np.corrcoef(Xcentered_values)\n",
    "        #for M\n",
    "        ytrgt=Ytrgt[1]\n",
    "        output_col=output_col_lst[1]\n",
    "    #     print(f\"\\nprinting the {k} indices closest to M={ytrgt}\")\n",
    "        unsorted_series=np.abs(df[output_col]-ytrgt)\n",
    "        indices_of_sorted=unsorted_series.argsort()\n",
    "        smallest_deviations=indices_of_sorted.loc[:k-1].values\n",
    "#         boo=unsorted_series.index.values==unsorted_series.loc[smallest_deviations[0]].values[0]\n",
    "#         for sd in smallest_deviations[1:]:\n",
    "#             sdd=unsorted_series.iloc[sd].values[0]\n",
    "#             boo|=unsorted_series.index.values==sdd\n",
    "    #     print(df.loc[smallest_deviations,cols])\n",
    "        #compute the boltzmann weighted mean m\n",
    "        output_disagreement_values=unsorted_series.iloc[indices_of_sorted].values[:k-1]#df.loc[boo,output_col].values\n",
    "        boltzman_weighted_mean=comp_boltzman_weighted_mean(output_disagreement_values,**kwargs)\n",
    "    #     print(f\"the boltzman_weighted_mean for the K={k} elite members was {boltzman_weighted_mean}\")\n",
    "        M2avg_lst.append(boltzman_weighted_mean)\n",
    "\n",
    "        #compute the boltzmann weighted average w.r.t. m\n",
    "        weight_values=comp_boltzman_weighted_weights(output_disagreement_values,**kwargs)\n",
    "#         elite_parameter_values=df.loc[boo].values#,cols]\n",
    "        elite_parameter_values=df.iloc[indices_of_sorted].values[:k-1]\n",
    "        dict_zip=dict(zip(list(df.columns),np.sum(weight_values*elite_parameter_values.T,axis=1)))\n",
    "        dict_out={}\n",
    "        dict_out[model_name+f'_top_trial_index']=int(smallest_deviations[0])\n",
    "        dict_bwm[model_name+f'_{output_col}']=dict_out\n",
    "        dict_out[model_name+f'_corrcoeff']=corrcoeff_values.copy()\n",
    "#         dict_out[model_name+f'_svd']=Xsvd_values.copy()\n",
    "        dict_out[model_name+f'_output_disagreement_values']=output_disagreement_values.copy()\n",
    "        dict_out[model_name+f'_dict_zip']=dict_zip\n",
    "    #     print(f\"the boltzman_weighted mean parameter for the K={k} elite members was {dict_out}\")\n",
    "    return dict_bwm,dict_out,dict_zip #,smallest_deviations_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.613996Z",
     "start_time": "2022-02-07T20:57:16.613986Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#DONE: compute the mean squared differences amongst either of the full models and then take the minimum.\n",
    "#TODO: take random linear combinations in the interpolating space and take the max 1000 randomly seeded values\n",
    "#TODO: generate ^that many random samples in d dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.614702Z",
     "start_time": "2022-02-07T20:57:16.614691Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kwargs={\n",
    "}\n",
    "dict_bwm,dict_out=compute_boltzman_defect_weighted_mean_et_alii(df=df_star,num_to_include=6,**kwargs)\n",
    "compute_boltzman_defect_weighted_mean_et_alii(\n",
    "    dg,#df,\n",
    "#     input_cols=['r', 'kappa', 'D', 'varkappa'],\n",
    "#     output_col_lst=['m', 'M'],\n",
    "#     model_name_lst=None,\n",
    "    num_to_include=6,\n",
    "    printing=False\n",
    "#     **kwargs,\n",
    ")\n",
    "df_bwm=pd.DataFrame(dict_bwm)\n",
    "df_bwm.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.615316Z",
     "start_time": "2022-02-07T20:57:16.615306Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(*dict_out)\n",
    "df_star.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.616174Z",
     "start_time": "2022-02-07T20:57:16.616163Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dict_bwm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# (optional) figure out which of the randomly generated interpolants of the star values looks the best for either model.  consider all rows in df_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.616973Z",
     "start_time": "2022-02-07T20:57:16.616963Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#TODO: merge and move to dev run .ipynb\n",
    "# intersection_dir='/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_15_ar_star.csv'\n",
    "intersection_dir='/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_17_ar_star.csv'\n",
    "df_star=pd.read_csv(intersection_dir)\n",
    "# df_star.head()\n",
    "\n",
    "input_cols=['rstar', 'kappa', 'D', 'astar']\n",
    "output_col_lst=['m', 'M']\n",
    "X=df_star[input_cols].values\n",
    "num_stars=X.shape[0]\n",
    "\n",
    "#TODO: make a num_samples by num_stars matrix\n",
    "num_samples=10000\n",
    "rarr=np.random.random(size=(num_samples,num_stars))\n",
    "# DONT: #TODO: normalize rarr.  this obliterates convex information space sampled\n",
    "# rarr=np.matmul(rarr,np.ones(rarr.shape[1]))\n",
    "# rarr.shape,np.sum(rarr,axis=1)\n",
    "random_parameter_values=np.matmul(rarr,X)\n",
    "#augment with arr\n",
    "r_values,kappa_values,D_values,varkappa_values=np.concatenate((X,random_parameter_values)).T\n",
    "\n",
    "#later #TODO: augment the 4 bwm parameters\n",
    "# df_bwm\n",
    "\n",
    "# #TODO: augment with corrcoeff_values projected onto 4x4\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.617867Z",
     "start_time": "2022-02-07T20:57:16.617856Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#TODO: fix Delta_M to be correct.  is it significantly larger?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:57:16.618745Z",
     "start_time": "2022-02-07T20:57:16.618734Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from inspect import getsource\n",
    "# print(getsource(LinearNDInterpolator))\n",
    "LinearNDInterpolator('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
