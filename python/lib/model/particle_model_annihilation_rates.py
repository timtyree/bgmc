import numpy as np, pandas as pd, os, sys
from scipy.interpolate.interpnd import LinearNDInterpolator
#particle_model_annihilation_rates.py
#Programmer: Tim Tyree
#Date: 1.3.2022

def recall_particle_model_interp(
    reflect=0,
    force_code=2,
    set_second=0,
    no_attraction=0,
    no_repulsion=0,
    L=10,
    testing=False, #True yields an extra runtimme of ~2 minutes
    printing=True,
    mode='vectorsummed', #'neighboronly',
    input_fn_dict=None,
    **kwargs):
    '''returns interp as a map from ['r','kappa','varkappa','D'] to
    a map from particle density to annihilation rate per unit area,
    where
        - r : reaction range
        - kappa : reaction rate
        - varkappa : attraction coefficient
        - D : diffusion coefficient

    interp uses linear interpolation of cached powerlaw fits to the results generated by ./bgmc/c/attractive/return_CollTimes.sh,
    which uses self-contained c and perl
    see 'generation of table of powerfits.ipynb' for consequent generation of powerlaw fits.

    modes are supported for mode in {'vectorsummed','neighboronly'}.
    the locations of the powerlaw fits from our inverse-powerlaw particle model can be specified by input_fn_dict.
    input_fn_dict=None defaults my file locations.

    Example Usage:
    interp=recall_particle_model_interp()

    Nota Bene:
    This function is written in a way that should be straight-forward to generalize.  Feel free to email me if interested here: tyree at physics dot ucsd dot edu.
    '''
    if mode=='vectorsummed':
        # vector-summed forces
        neighbor=0
        if input_fn_dict is not None:
            input_fn=input_fn_dict[mode]
        else:
            input_fn=f"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_17_all_powerlaw_fits.csv"
    elif mode=='neighboronly':
        #neighbor-only forces
        neighbor=1
        if input_fn_dict is not None:
            input_fn=input_fn_dict[mode]
        else:
            input_fn=f"/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/run_19_all_powerlaw_fits.csv"
    else:
        raise "Error: mode not yet implemented!"

    #load the powerlaw fits
    df=pd.read_csv(input_fn)
    if printing:
        print(f"estimated runtime is ~{20+120*int(testing)} seconds for 17988 training samples...")
    #query the DataFrame by parameters to be fixed
    query =(df.set_second==set_second)&(df.reflect==reflect)
    query&=(df.no_repulsion==no_repulsion)&(df.no_attraction==no_attraction)
    query&=(df.neighbor==neighbor)&(df.force_code==force_code)
    # query&=df.r==r
    # query&=df.kappa==kappa
    # query&=df.D==D
    query&=df.L==L
    # query&=df.varkappa==varkappa
    dg=df[query]

    #define parameters to be varied
    # input_cols=['r','D','varkappa']#~2 minute runtime?
    input_cols=['r','kappa','varkappa','D']#~2 minute runtime
    # output_cols=['m','Delta_m','M','Delta_M']#~2 minute runtime
    output_cols=['m','M']#2.75 minute runtime paradoxically...
    #inputs:dg,input_cols,output_col
    #output: fitted model

    Xall=dg[input_cols].values
    yall=dg[output_cols].values

    X=Xall.copy()
    y=yall.copy()
    m = len(y) # number of training examples
    if printing:
        print(f'number of training examples is {m:d}....')

    interp = LinearNDInterpolator(X, y)
    # interp = CloughTocher2DInterpolator(X, y) #leads to weird nonlinearities in sparse data
    if printing:
        print(f"training complete!")
    if testing:
        yhat = interp(X)
        if printing:
            print(f"shape of X {X.shape} --> shape of y=yhat {yhat.shape}")
            print(f"Example Usage:\nyhat=interp(X)")

        rmse=np.sqrt(np.mean((yhat-y)**2))
        if printing:
            print(f"the rmse of simple interpolation is {rmse:.4f}")
    return interp
