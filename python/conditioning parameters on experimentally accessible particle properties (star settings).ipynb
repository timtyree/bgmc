{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conditioning parameters on experimentally accessible particle properties\n",
    "Tim Tyree<br>\n",
    "9.29.2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:55:55.116991Z",
     "start_time": "2022-09-05T02:55:53.002505Z"
    }
   },
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "from lib.my_initialization import *\n",
    "import random,scipy\n",
    "from scipy import stats\n",
    "\n",
    "import random,scipy\n",
    "from scipy.interpolate import LinearNDInterpolator\n",
    "from scipy.interpolate import CloughTocher2DInterpolator\n",
    "import matplotlib as mpl #for colorbar\n",
    "from scipy import stats\n",
    "#DONE: hook this routine up to dask\n",
    "#DONT: hook this routine up to dask_cuda\n",
    "\n",
    "from lib.viewer.gener_q_vs_w_for_df import *\n",
    "\n",
    "from lib.my_initialization import *\n",
    "from lib import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:55:58.723604Z",
     "start_time": "2022-09-05T02:55:57.010453Z"
    }
   },
   "outputs": [],
   "source": [
    "import dask_cudf,cudf,cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:55:58.847873Z",
     "start_time": "2022-09-05T02:55:58.822330Z"
    }
   },
   "outputs": [],
   "source": [
    "# import cupyx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:55:58.974542Z",
     "start_time": "2022-09-05T02:55:58.951359Z"
    }
   },
   "outputs": [],
   "source": [
    "# import cucim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:55:59.080328Z",
     "start_time": "2022-09-05T02:55:59.054667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fk_pbc lr_pbc fk_ncbc lr_ncbc\n"
     ]
    }
   ],
   "source": [
    "wjr=recall_powerlaw_fits_to_full_models()\n",
    "print(*wjr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:58:07.559170Z",
     "start_time": "2022-09-05T02:58:07.463754Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lib.lib_care.measure._find_contours_cy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib_care\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeasure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlevel_sets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m comp_longest_level_set_and_smooth\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#DONE: compute the level set contours\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_powerlaw_levelsets\u001b[39m(x1_values,x2_values,Y_values,model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfk_pbc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m                               navg\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,m_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,M_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      5\u001b[0m                               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "File \u001b[0;32m~/Documents/GitHub/bgmc/python/lib/lib_care/measure/__init__.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterpolate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintersection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_find_contours\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_contours\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils_find_contours\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils_find_tips\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/bgmc/python/lib/lib_care/measure/_find_contours.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_find_contours_cy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _get_contour_segments\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_find_contours_pbc_cy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _get_contour_segments_pbc\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deque\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lib.lib_care.measure._find_contours_cy'"
     ]
    }
   ],
   "source": [
    "# from lib.lib_care.measure.level_sets import comp_longest_level_set_and_smooth\n",
    "# #DONE: compute the level set contours\n",
    "# def compute_powerlaw_levelsets(x1_values,x2_values,Y_values,model_name='fk_pbc',\n",
    "#                               navg=50,m_col=1,M_col=0,\n",
    "#                               **kwargs):\n",
    "#     num_points=x1_values.shape[0]*x1_values.shape[1]\n",
    "#     X_values=np.stack((x1_values,x2_values)).reshape((num_points,2))\n",
    "#     output_col='m'\n",
    "#     level=wjr[model_name][output_col];print(level)\n",
    "#     y=Y_values[...,m_col].flatten()\n",
    "#     contour_m_values=comp_longest_level_set_and_smooth(X_values,y,level,navg=navg)\n",
    "\n",
    "#     output_col='M'\n",
    "#     level=wjr[model_name][output_col];print(level)\n",
    "#     y=Y_values[...,M_col].flatten()\n",
    "#     contour_M_values=comp_longest_level_set_and_smooth(X_values,y,level,navg=navg)\n",
    "#     return contour_m_values,contour_M_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load and select data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:56:19.140800Z",
     "start_time": "2022-09-05T02:56:19.118525Z"
    }
   },
   "outputs": [],
   "source": [
    "#didn't work for LinearNDInterpolator\n",
    "# from numba import cuda\n",
    "# @cuda.jit\n",
    "# def multiply(in_col, out_col, multiplier):\n",
    "#     i = cuda.grid(1)\n",
    "#     if i < in_col.size: # boundary guard\n",
    "#         out_col[i] = in_col[i] * multiplier\n",
    "# interp.__defaults__=None\n",
    "# cinterp=cuda.jit(interp)\n",
    "# def foo(x):\n",
    "#     return x\n",
    "# foo.__defaults__\n",
    "# blockspergrid=16\n",
    "# threadsperblock=16\n",
    "# cYhat=cinterp[blockspergrid, threadsperblock](X.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:56:21.146764Z",
     "start_time": "2022-09-05T02:56:20.142929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there were 35280 rows found in the list of csv files\n"
     ]
    }
   ],
   "source": [
    "#list of files to include from the map from particle properties to powerlaw fits\n",
    "data_folder='/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/'\n",
    "# input_fn_lst=[\n",
    "#     'run_15_all_powerlaw_fits.csv',\n",
    "#     'run_16_all_powerlaw_fits.csv',\n",
    "#     'run_17_all_powerlaw_fits.csv',\n",
    "#     'run_18_all_powerlaw_fits.csv',\n",
    "# ]\n",
    "input_fn_lst=[\n",
    "    'run_25_all_powerlaw_fits.csv',\n",
    "    'run_25_all_powerlaw_fits.csv'\n",
    "]\n",
    "\n",
    "#load the data\n",
    "os.chdir(data_folder)\n",
    "ddf=dask_cudf.read_csv(input_fn_lst,npartitions=4)\n",
    "df=cudf.DataFrame(ddf.compute())\n",
    "df.dropna(inplace=True)\n",
    "print(f\"there were {df.shape[0]} rows found in the list of csv files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:56:21.480000Z",
     "start_time": "2022-09-05T02:56:21.440365Z"
    }
   },
   "outputs": [],
   "source": [
    "##################### \n",
    "#compute the map from input_cols=['r','kappa','D','varkappa'] to output_col='m'\n",
    "##################### ~1min run time for fitting, ~4min for testing\n",
    "#define constant parameters\n",
    "# reflect=0\n",
    "# force_code=2\n",
    "# set_second=0\n",
    "# neighbor=0\n",
    "# no_attraction=0\n",
    "# no_repulsion=0\n",
    "# L=10\n",
    "\n",
    "\n",
    "#define constant parameters\n",
    "reflect=0\n",
    "force_code=2\n",
    "set_second=0\n",
    "neighbor=1\n",
    "no_attraction=0\n",
    "no_repulsion=0\n",
    "L=5\n",
    "\n",
    "#query the DataFrame\n",
    "query =(df.set_second==set_second)&(df.reflect==reflect)\n",
    "query&=(df.no_repulsion==no_repulsion)&(df.no_attraction==no_attraction)\n",
    "query&=(df.neighbor==neighbor)&(df.force_code==force_code)\n",
    "# query&=df.r==r\n",
    "# query&=df.kappa==kappa\n",
    "# query&=df.D==D\n",
    "query&=df.L==L\n",
    "# query&=df.varkappa==varkappa\n",
    "# query&=df.x0==x0\n",
    "dg=df[query]\n",
    "assert dg.shape[0]>0\n",
    "# #define parameters to be varied\n",
    "# # input_cols=['r','kappa']#TODO(if rmse is still zero here...): simply repeat with varkappa,D fixed\n",
    "# # input_cols=['r','D','varkappa']#,x0\n",
    "# input_cols=['r','kappa','D','varkappa']#,x0\n",
    "# output_col='m'\n",
    "# #inputs:dg,input_cols,output_col\n",
    "# #output: fitted model\n",
    "\n",
    "# Xall=dg[input_cols].values \n",
    "# yall=dg[output_col].values\n",
    "# X=Xall.get()\n",
    "# y=yall.get()\n",
    "# m = len(y) # number of training examples\n",
    "# print(f'number of training examples is {m:d}')\n",
    "\n",
    "# interp = LinearNDInterpolator(X, y)\n",
    "# # interp = CloughTocher2DInterpolator(X, y)\n",
    "# yhat = interp(X)\n",
    "# boona=np.isnan(yhat)\n",
    "# rmse=np.sqrt(np.mean((yhat[~boona]-y[~boona])**2))\n",
    "# print(f\"the rmse of simple interpolation is {rmse:.4f}\")\n",
    "# print(f\"shape of X {X.shape} --> shape of y=yhat {yhat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute a function that maps r,kappa,varkappa,D to M,m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Results__ \n",
    "\n",
    "#DONE: was the rmse high because I was using multiple slices with reflect=0 and 1? Yes.\n",
    "- linear nd interpolation was consistent to 1e-5 for fill_value=True versus False.\n",
    "- linear nd interpolation was consistent to 1e-16 for one output column at a time versus all 4 output columns\n",
    "- linear nd interpolation trained on D=0.2 data had an rmse_M = 0.0339837, which is much smaller than the unconstrained rmse_M = 0.7284194\n",
    "    - __Corollary__, if I have the brute force grid search already present, then it makes sense to use it in interpolation\n",
    " \n",
    "#DONE: confirmed slicing the dataframe fixed everything...\n",
    "- interpolating from d=4 to d=1 gave rmse_m=0.001 when constraining to periodic boundary conditions and the other procedural parameters to a single category of function, which was ~7X better than forgetting about that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-05T02:51:13.090Z"
    }
   },
   "outputs": [],
   "source": [
    "# boo=df['D']==0.1\n",
    "#extract features X=(r,kappa,varkappa,D) to labels Y=(M,m) as cupy arrays\n",
    "X_col_lst=['r','kappa','varkappa','D']\n",
    "# X_col_lst=['varkappa','D','r','kappa']\n",
    "Y_col_lst=['M','m', 'Delta_M','Delta_m', 'Rsq']\n",
    "# Y_col_lst=\"M\"#['M']#,'m', 'Delta_M','Delta_m']\n",
    "# Xall=dg.loc[boo,X_col_lst].values\n",
    "# Yall=dg.loc[boo,Y_col_lst].values\n",
    "Xall=dg[X_col_lst].values\n",
    "Yall=dg[Y_col_lst].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-05T02:50:58.997Z"
    }
   },
   "outputs": [],
   "source": [
    "#compute the linear interpolating function from (r,kappa,varkappa,D) to (M,m)\n",
    "#TODO: find a cupy implementation of LinearNDInterpolator\n",
    "X=Xall.get()\n",
    "Y=Yall.get()\n",
    "\n",
    "# xgrid = np.mgrid[-1:1:50j, -1:1:50j]\n",
    "# interp = scipy.interpolate.RBFInterpolator(X, Y, \n",
    "#                                            neighbors=15,\n",
    "# #                                            smoothing=1.,kernel='linear')#(xflat){'thin_plate_spline', 'cubic', 'quintic', 'linear'}.\n",
    "# #                                            smoothing=0.001,kernel='linear')#(xflat){'thin_plate_spline', 'cubic', 'quintic', 'linear'}.\n",
    "#                                            smoothing=0.001,kernel='gaussian',epsilon=0.1)#(xflat){'thin_plate_spline', 'cubic', 'quintic', 'linear'}.\n",
    "\n",
    "# #DONE: test if the imperfect interpolation is the result of having multiple target values\n",
    "interp=LinearNDInterpolator(points=X, values=Y, rescale=True)\n",
    "# interp=LinearNDInterpolator(points=X, values=Y, rescale=False)\n",
    "# # interp=LinearNDInterpolator(points=X, values=Y)#, fill_value=np.nan, rescale=True)\n",
    "# # interp=LinearNDInterpolator(points=X.get(), values=Y.get(), fill_value=np.nan, rescale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.951925Z",
     "start_time": "2022-09-05T02:19:52.951911Z"
    }
   },
   "outputs": [],
   "source": [
    "# from inspect import signature\n",
    "\n",
    "# signature(interp).parameters#, follow_wrapped=True)\n",
    "# Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.953315Z",
     "start_time": "2022-09-05T02:19:52.953301Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Yhat=interp(X)\n",
    "print('the inputs can be evaluated!')\n",
    "\n",
    "se=(cp.array(Yhat)-Yall)**2\n",
    "boona=cp.isnan(se[:,0])\n",
    "# Y[boona,0],cp.array(Yhat)[boona,0]  #was one row only when I looked\n",
    "mse=cp.mean(se[~boona],axis=0)\n",
    "rmse=cp.sqrt(mse)\n",
    "# interp=LinearNDInterpolator(points=X.get(), values=Y.get())#, fill_value=np.nan, rescale=True)\n",
    "print(f\"the rmse of linear interpolation is\\n\\t{rmse}\\nfor\\t{Y_col_lst}\")\n",
    "\n",
    "# # # DONE: test rmse of the linear RBFInterpolator with 15 neighbors\n",
    "# the inputs can be evaluated!\n",
    "# the rmse of linear interpolation is\n",
    "# \t[0.0933669  0.00072217 0.0453468  0.00012483]\n",
    "# for\t['M', 'm', 'Delta_M', 'Delta_m']\n",
    "\n",
    "# # DONE: test rmse of the linear RBFInterpolator with 300 neighbors\n",
    "# the inputs can be evaluated!\n",
    "# the rmse of linear interpolation is\n",
    "# \t[0.08795691 0.00070626 0.04275492 0.00012456]\n",
    "# for\t['M', 'm', 'Delta_M', 'Delta_m']\n",
    "\n",
    "# # # DONE: test rmse of the linear RBFInterpolator with 3 neighbors\n",
    "# the inputs can be evaluated!\n",
    "# the rmse of linear interpolation is\n",
    "# \t[1.47973001e-01 9.47869258e-04 6.10703994e-02 1.28425583e-04]\n",
    "# for\t['M', 'm', 'Delta_M', 'Delta_m']\n",
    "\n",
    "# DONE(if rmse is still too big here...): simply repeat with varkappa,D fixed\n",
    "# the rmse of simple interpolation is 0.0010\n",
    "# #for rescale=False,\n",
    "# the rmse of linear interpolation is\n",
    "# \t[0.11341626 0.00096018 0.05280392 0.00017267]\n",
    "# for\t['M', 'm', 'Delta_M', 'Delta_m']\n",
    "\n",
    "# #for rescale=True,\n",
    "# the rmse of linear interpolation is\n",
    "# \t[0.11341453 0.00096017 0.05280311 0.00017267]\n",
    "# for\t['M', 'm', 'Delta_M', 'Delta_m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.955067Z",
     "start_time": "2022-09-05T02:19:52.955050Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: fix D and varkappa to reasonable values for the FK,LR models\n",
    "#FK\n",
    "D=0.365#238 #+- 0.004171  \n",
    "varkappa=9.524#+-1.517 #direct \"measurement\"\n",
    "varkappa=1.9 #eyeballed from a versus r*kappa**p for p = 1 or 0.5\n",
    "#LR\n",
    "# D=0.586#055 #+- 0.087553  #didn't yield the desired level sets\n",
    "# varkappa=96.614#+-20.658\n",
    "# varkappa=19 #eyeballed from a versus r*kappa**p for p = 1 or 0.5\n",
    "# varkappa=9.5\n",
    "# D=1#didn't help\n",
    "# varkappa=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.956588Z",
     "start_time": "2022-09-05T02:19:52.956570Z"
    }
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.957973Z",
     "start_time": "2022-09-05T02:19:52.957957Z"
    }
   },
   "outputs": [],
   "source": [
    "#make a uniform grid over two axes at r,kappa conditioned on varkappa,D\n",
    "x1col=0\n",
    "x2col=1\n",
    "num_samples=100\n",
    "\n",
    "xi=[]\n",
    "x1=X[:,x1col]\n",
    "xi.append(np.linspace(np.min(x1), np.max(x1),num_samples))\n",
    "x2=X[:,x2col]\n",
    "xi.append(np.linspace(np.min(x2), np.max(x2),num_samples))\n",
    "XI=np.meshgrid(*xi)\n",
    "# print(len(XI))\n",
    "x1_values=XI[0]\n",
    "x2_values=XI[1]\n",
    "\n",
    "#holding varkappa and D fixed, interpolate from r,kappa to Yhat\n",
    "# np.array(list(zip(XI))).shape\n",
    "gridshape=x1_values.shape\n",
    "X_values=np.array(list(zip((x1_values.flatten(),x2_values.flatten(),varkappa+0.*x1_values.flatten(),D+0.*x2_values.flatten()))))[:,0,:].T#[:,fixed_row,:].T\n",
    "\n",
    "\n",
    "#compute the interpolated values of y on this 2D grid for each \n",
    "# interp = LinearNDInterpolator(X, y)\n",
    "# interp = CloughTocher2DInterpolator(X, y)\n",
    "Y_values = interp(X_values).reshape(gridshape[0],gridshape[1],len(Y_col_lst))\n",
    "Y_values.shape,X_values.shape,x1_values.shape\n",
    "# print(np.max(x1_values))\n",
    "\n",
    "# return x1_values.shape,x2_values.shape,Y_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LinearNDFit is the problem for why I can't get contours__ The input m values include 1.6~1.8, while interpolated values apparently do not.\n",
    "\n",
    "TODO: interpolate using radial basis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.959227Z",
     "start_time": "2022-09-05T02:19:52.959211Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(Y_values[:,1].flatten(),density=True)\n",
    "plt.hist(Y[:,1].flatten(),density=True)\n",
    "print(f\"are we seeing smaller exponents 1.6~1.8?\")\n",
    "print((Y[:,1].flatten().min(),Y[:,1].flatten().max()))\n",
    "print((Y_values[:,1].flatten().min(),Y_values[:,1].flatten().max()))\n",
    "plt.ylabel(r'$\\nu$')\n",
    "plt.xlim([0,10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.960478Z",
     "start_time": "2022-09-05T02:19:52.960461Z"
    }
   },
   "outputs": [],
   "source": [
    "from lib.lib_care.measure.level_sets import comp_longest_level_set_and_smooth\n",
    "#TODO: compute the level set contours\n",
    "def compute_powerlaw_levelsets(x1_values,x2_values,Y_values,model_name='fk_pbc',\n",
    "                              navg=50,m_col=1,M_col=0,\n",
    "                              **kwargs):\n",
    "    num_points=x1_values.shape[0]*x1_values.shape[1]\n",
    "    X_values=np.stack((x1_values,x2_values)).reshape((num_points,2))\n",
    "    output_col='m'\n",
    "    level=wjr[model_name][output_col];print(level)\n",
    "    y=Y_values[...,m_col].flatten()\n",
    "    contour_m_values=comp_longest_level_set_and_smooth(X_values,y,level,navg=navg)\n",
    "\n",
    "    output_col='M'\n",
    "    level=wjr[model_name][output_col];print(level)\n",
    "    y=Y_values[...,M_col].flatten()\n",
    "    contour_M_values=comp_longest_level_set_and_smooth(X_values,y,level,navg=navg)\n",
    "    return contour_m_values,contour_M_values\n",
    "\n",
    "\n",
    "# - TODO: find any a:=varkappa value that supports power law fits for both full models\n",
    "# - TODO: find an upper and lower bound on the a:=varkappa values that support power law fits for both full models\n",
    "try:\n",
    "    contour_m_values,contour_M_values = compute_powerlaw_levelsets(x1_values,x2_values,Y_values,model_name='fk_pbc',\n",
    "                              navg=50,m_col=1,M_col=0)\n",
    "    print(f\"---: fenton-karma model might be supported\")\n",
    "except AssertionError as e:\n",
    "    print(f\"{e}: fenton-karma model not supported anywhere\")\n",
    "    \n",
    "try:\n",
    "    contour_m_values,contour_M_values = compute_powerlaw_levelsets(x1_values,x2_values,Y_values,model_name='lr_pbc',\n",
    "                              navg=50,m_col=1,M_col=0)\n",
    "    print(f\"---: luo-rudy model might be supported\")\n",
    "except AssertionError as e:\n",
    "    print(f\"{e}: luo-rudy     model not supported anywhere\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.961918Z",
     "start_time": "2022-09-05T02:19:52.961905Z"
    }
   },
   "outputs": [],
   "source": [
    "# #m\n",
    "# y_values=Y_values[...,1]\n",
    "# #M\n",
    "# y_values=Y_values[...,0]\n",
    "# print((x1_values.shape,x2_values.shape,y_values.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.963281Z",
     "start_time": "2022-09-05T02:19:52.963268Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot the interpolated m (left) and the interpolated M (right) for each pixel.\n",
    "#visualize r versus kappa conditioned on varkappa and D\n",
    "x1lim=[np.min(x1_values),np.max(x1_values)]\n",
    "x2lim=[np.min(x2_values),np.max(x2_values)]\n",
    "fontsize=18\n",
    "xlabel=r'$r$ (cm)'\n",
    "ylabel=r'$\\kappa$ (Hz)'\n",
    "cmap = mpl.cm.cool\n",
    "\n",
    "#columnal kwargs\n",
    "vmin_lst=[1,0]\n",
    "vmax_lst=[3,30]\n",
    "output_col_lst=[1,0]#['m','M']\n",
    "#kwargs by row\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(11,5))\n",
    "cmaps = ['RdBu_r', 'viridis']\n",
    "title_lst=[\n",
    "    f'a={varkappa}'+r'cm$^2$/s'+f', D={D}'+r'cm$^2$/s'+f'\\n',\n",
    "    ''#f'M={M}'+r'cm$^{2(\\nu-1)}$/s, $\\nu$'+f'={m}\\n'\n",
    "]\n",
    "clabel_lst=[r'$\\nu$',r'M cm$^{2(\\nu-1)}$/s']\n",
    "nsamples=1000\n",
    "for col in range(len(output_col_lst)):\n",
    "#     #extract target output value to fit to\n",
    "#     output_col=output_col_lst[col]\n",
    "#     yall=dg[output_col].values\n",
    "# #     for row in range(2):\n",
    "# #       #  restrict to fixed reaction range\n",
    "# #         r=r_lst[row]\n",
    "# #         title=title_foo(r)#f'r = {r:.1f} cm'\n",
    "#         boo=Xall[:,0]==r\n",
    "#         X=Xall[boo,1:3].copy()  #make the x,y axis the 2nd and 3rd columns of X\n",
    "#         y=yall[boo].copy()\n",
    "#         #TODO: compute the m,M fits\n",
    "#         #TODO: compute the interpolated values of y on this 2D grid\n",
    "#         interp = LinearNDInterpolator(X, y)\n",
    "    output_col=output_col_lst[col]\n",
    "    y_values=Y_values[...,output_col]\n",
    "    \n",
    "    ax = axs[col]\n",
    "    vmin=vmin_lst[col]\n",
    "    vmax=vmax_lst[col]\n",
    "\n",
    "#         vmin=np.quantile(y_values.flatten(),0.25)\n",
    "#         vmax=np.quantile(y_values.flatten(),0.75)\n",
    "    pcm=ax.pcolormesh(x1_values, x2_values, y_values, vmin=vmin, vmax=vmax, cmap=cmaps[col],shading='auto')\n",
    "\n",
    "#TODO: interpolate in 2D and plot the levelsets\n",
    "#         interp_2d = CloughTocher2DInterpolator(X, y)\n",
    "\n",
    "    \n",
    "#         ax.set_xlim(x1lim)\n",
    "#         ax.set_ylim(x2lim)\n",
    "    title=title_lst[col]\n",
    "    ax.set_title(title,fontsize=fontsize)\n",
    "    format_plot(ax, xlabel, ylabel, fontsize)#, use_loglog=False\n",
    "#     print(np.max(x1_values))\n",
    "#     fig.colorbar(pcm, ax=[axs[0, col]], location='top', shrink=0.6)\n",
    "    cbar=fig.colorbar(pcm, ax=axs[col],shrink=0.6)#,label=output_col)\n",
    "    cbar.ax.tick_params(labelsize=fontsize)\n",
    "    cbar.set_label(clabel_lst[col], fontsize=fontsize)    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.964513Z",
     "start_time": "2022-09-05T02:19:52.964496Z"
    }
   },
   "outputs": [],
   "source": [
    "# num_points=x1_values.shape[0]*x1_values.shape[1]\n",
    "# X=np.stack((x1_values,x2_values)).reshape((num_points,2))\n",
    "# X.shape\n",
    "model_name='fk_pbc'\n",
    "print(model_name)\n",
    "print_dict(wjr[model_name])\n",
    "print('')\n",
    "model_name='lr_pbc'\n",
    "print(model_name)\n",
    "print_dict(wjr[model_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T22:16:55.161497Z",
     "start_time": "2021-09-28T22:16:55.130289Z"
    }
   },
   "source": [
    "__Looking at the a versus r*kappa**p plot of the star values of run 18...__\n",
    "We would expect a_FK~1.9\n",
    "\n",
    "And a_LR~9.5\n",
    "\n",
    "Which has a_LR/a_F~9.5/1.9=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T23:17:54.158125Z",
     "start_time": "2021-09-28T23:17:54.131100Z"
    }
   },
   "source": [
    "__Looking at the apparent a from the full models in care...__\n",
    "We would expect a_FK~9.524\n",
    "\n",
    "And a_LR~96.614\n",
    "\n",
    "Which has a_LR/a_F~2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.965943Z",
     "start_time": "2022-09-05T02:19:52.965926Z"
    }
   },
   "outputs": [],
   "source": [
    "D=0.365#238 #+- 0.004171  \n",
    "varkappa=9.524#+-1.517 #direct \"measurement\"\n",
    "varkappa=1.9 #eyeballed from a versus r*kappa**p for p = 1 or 0.5\n",
    "#LR\n",
    "D=0.586#055 #+- 0.087553  #didn't yield the desired level sets\n",
    "# varkappa=96.614#+-20.658\n",
    "# varkappa=19 #eyeballed from a versus r*kappa**p for p = 1 or 0.5\n",
    "19/9.524"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The percent disagreement for either model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.967136Z",
     "start_time": "2022-09-05T02:19:52.967124Z"
    }
   },
   "outputs": [],
   "source": [
    "96.614/19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-05T02:54:33.412Z"
    }
   },
   "outputs": [],
   "source": [
    "9.524/1.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... __Result__ if my estimate for a were 5X smaller, then I would get an intersection point?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fix a,D andthen compute a function that maps r,kappa to M,m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T05:20:17.538585Z",
     "start_time": "2022-09-05T05:20:17.495459Z"
    }
   },
   "outputs": [],
   "source": [
    "#didn't work for LinearNDInterpolator\n",
    "# from numba import cuda\n",
    "# @cuda.jit\n",
    "# def multiply(in_col, out_col, multiplier):\n",
    "#     i = cuda.grid(1)\n",
    "#     if i < in_col.size: # boundary guard\n",
    "#         out_col[i] = in_col[i] * multiplier\n",
    "# interp.__defaults__=None\n",
    "# cinterp=cuda.jit(interp)\n",
    "# def foo(x):\n",
    "#     return x\n",
    "# foo.__defaults__\n",
    "# blockspergrid=16\n",
    "# threadsperblock=16\n",
    "# cYhat=cinterp[blockspergrid, threadsperblock](X.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T05:20:19.082096Z",
     "start_time": "2022-09-05T05:20:19.059547Z"
    }
   },
   "outputs": [],
   "source": [
    "# #list of files to include from the map from particle properties to powerlaw fits\n",
    "# data_folder='/home/timothytyree/Documents/GitHub/bgmc/python/data/osg_output/'\n",
    "# input_fn_lst=[\n",
    "# #     'run_15_all_powerlaw_fits.csv',\n",
    "# #     'run_16_all_powerlaw_fits.csv',\n",
    "#     'run_17_all_powerlaw_fits.csv',\n",
    "# #     'run_18_all_powerlaw_fits.csv',\n",
    "# ]\n",
    "\n",
    "# #load the data\n",
    "# os.chdir(data_folder)\n",
    "# ddf=dask_cudf.read_csv(input_fn_lst,npartitions=4)\n",
    "# df=cudf.DataFrame(ddf.compute())\n",
    "# df.dropna(inplace=True)\n",
    "# print(f\"there were {df.shape[0]} rows found in the list of csv files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T05:20:19.359025Z",
     "start_time": "2022-09-05T05:20:19.275543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m</th>\n",
       "      <th>Delta_m</th>\n",
       "      <th>M</th>\n",
       "      <th>Delta_M</th>\n",
       "      <th>Rsq</th>\n",
       "      <th>rmse</th>\n",
       "      <th>rmse_full</th>\n",
       "      <th>model_name_full</th>\n",
       "      <th>q_min</th>\n",
       "      <th>q_max</th>\n",
       "      <th>...</th>\n",
       "      <th>x0</th>\n",
       "      <th>L</th>\n",
       "      <th>force_code</th>\n",
       "      <th>neighbor</th>\n",
       "      <th>reflect</th>\n",
       "      <th>set_second</th>\n",
       "      <th>no_repulsion</th>\n",
       "      <th>no_attraction</th>\n",
       "      <th>dt</th>\n",
       "      <th>Dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.231491</td>\n",
       "      <td>0.160727</td>\n",
       "      <td>93.361321</td>\n",
       "      <td>36.833594</td>\n",
       "      <td>0.996631</td>\n",
       "      <td>0.523422</td>\n",
       "      <td>3.733662</td>\n",
       "      <td>lr_pbc</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.990970</td>\n",
       "      <td>0.063111</td>\n",
       "      <td>25.768610</td>\n",
       "      <td>4.887806</td>\n",
       "      <td>0.997652</td>\n",
       "      <td>0.268464</td>\n",
       "      <td>1.689743</td>\n",
       "      <td>lr_pbc</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.096149</td>\n",
       "      <td>0.062995</td>\n",
       "      <td>29.023787</td>\n",
       "      <td>5.132623</td>\n",
       "      <td>0.997889</td>\n",
       "      <td>0.201797</td>\n",
       "      <td>2.107838</td>\n",
       "      <td>lr_pbc</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.938888</td>\n",
       "      <td>0.073003</td>\n",
       "      <td>16.435418</td>\n",
       "      <td>2.756748</td>\n",
       "      <td>0.998556</td>\n",
       "      <td>0.101718</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>fk_ncbc</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.353145</td>\n",
       "      <td>0.071580</td>\n",
       "      <td>7.303514</td>\n",
       "      <td>1.181615</td>\n",
       "      <td>0.997837</td>\n",
       "      <td>0.068909</td>\n",
       "      <td>0.134410</td>\n",
       "      <td>fk_pbc</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          m   Delta_m          M    Delta_M       Rsq      rmse  rmse_full  \\\n",
       "0  4.231491  0.160727  93.361321  36.833594  0.996631  0.523422   3.733662   \n",
       "1  1.990970  0.063111  25.768610   4.887806  0.997652  0.268464   1.689743   \n",
       "2  2.096149  0.062995  29.023787   5.132623  0.997889  0.201797   2.107838   \n",
       "3  2.938888  0.073003  16.435418   2.756748  0.998556  0.101718   0.770270   \n",
       "4  2.353145  0.071580   7.303514   1.181615  0.997837  0.068909   0.134410   \n",
       "\n",
       "  model_name_full  q_min  q_max  ...  x0  L  force_code  neighbor  reflect  \\\n",
       "0          lr_pbc   0.24    0.7  ...   0  5           2         1        0   \n",
       "1          lr_pbc   0.24    0.7  ...   0  5           2         1        0   \n",
       "2          lr_pbc   0.24    0.7  ...   0  5           2         1        0   \n",
       "3         fk_ncbc   0.24    0.7  ...   0  5           2         1        0   \n",
       "4          fk_pbc   0.24    0.7  ...   0  5           2         1        0   \n",
       "\n",
       "   set_second  no_repulsion  no_attraction       dt       Dt  \n",
       "0           0             0              0  0.00001  0.00001  \n",
       "1           0             0              0  0.00001  0.00001  \n",
       "2           0             0              0  0.00001  0.00001  \n",
       "3           0             0              0  0.00001  0.00001  \n",
       "4           0             0              0  0.00001  0.00001  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T05:20:20.255892Z",
     "start_time": "2022-09-05T05:20:20.203624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09  0.114]\n",
      "[1.553 9.969]\n"
     ]
    }
   ],
   "source": [
    "D_values=np.array(sorted(set(df.D.values.get())))#cm^2/s\n",
    "varkappa_values=np.array(sorted(set(df.varkappa.values.get())))#1/s\n",
    "print(D_values)\n",
    "print(varkappa_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T05:20:22.331909Z",
     "start_time": "2022-09-05T05:20:22.309557Z"
    }
   },
   "outputs": [],
   "source": [
    "# #TODO: fix D and varkappa to reasonable values for the FK,LR models\n",
    "# #FK\n",
    "# D=0.365#238 #+- 0.004171  \n",
    "# varkappa=9.524#+-1.517 #direct \"measurement\"\n",
    "# varkappa=1.9 #eyeballed from a versus r*kappa**p for p = 1 or 0.5\n",
    "# #LR\n",
    "# # D=0.586#055 #+- 0.087553  #didn't yield the desired level sets\n",
    "# # varkappa=96.614#+-20.658\n",
    "# # varkappa=19 #eyeballed from a versus r*kappa**p for p = 1 or 0.5\n",
    "# # varkappa=9.5\n",
    "# # D=1#didn't help\n",
    "# # varkappa=1.\n",
    "\n",
    "\n",
    "# #~FK\n",
    "# D=0.3\n",
    "# varkappa=2\n",
    "# # #~LR\n",
    "# # D=0.6\n",
    "# # varkappa=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T05:20:23.238098Z",
     "start_time": "2022-09-05T05:20:23.214342Z"
    }
   },
   "outputs": [],
   "source": [
    "##################### \n",
    "#compute the map from input_cols=['r','kappa','D','varkappa'] to output_col='m'\n",
    "##################### ~1min run time for fitting, ~4min for testing\n",
    "#define constant parameters\n",
    "reflect=0\n",
    "force_code=2\n",
    "set_second=0\n",
    "neighbor=0\n",
    "no_attraction=0\n",
    "no_repulsion=0\n",
    "# kappa=100\n",
    "L=10\n",
    "\n",
    "#query the DataFrame\n",
    "query =(df.set_second==set_second)&(df.reflect==reflect)\n",
    "query&=(df.no_repulsion==no_repulsion)&(df.no_attraction==no_attraction)\n",
    "query&=(df.neighbor==neighbor)&(df.force_code==force_code)\n",
    "# query&=df.r==r\n",
    "# query&=df.kappa==kappa\n",
    "# query&=cp.isclose(df.D,D)\n",
    "query&=df.L==L\n",
    "# query&=df.varkappa==varkappa#cp.isclose(df.D,D)\n",
    "# query&=df.x0==x0\n",
    "dg=df[query]\n",
    "query_template=query.copy()\n",
    "dg.head()\n",
    "# #define parameters to be varied\n",
    "# # input_cols=['r','kappa']#TODO(if rmse is still zero here...): simply repeat with varkappa,D fixed\n",
    "# # input_cols=['r','D','varkappa']#,x0\n",
    "# input_cols=['r','kappa','D','varkappa']#,x0\n",
    "# output_col='m'\n",
    "# #inputs:dg,input_cols,output_col\n",
    "# #output: fitted model\n",
    "\n",
    "# Xall=dg[input_cols].values \n",
    "# yall=dg[output_col].values\n",
    "# X=Xall.get()\n",
    "# y=yall.get()\n",
    "# m = len(y) # number of training examples\n",
    "# print(f'number of training examples is {m:d}')\n",
    "\n",
    "# interp = LinearNDInterpolator(X, y)\n",
    "# # interp = CloughTocher2DInterpolator(X, y)\n",
    "# yhat = interp(X)\n",
    "# boona=np.isnan(yhat)\n",
    "# rmse=np.sqrt(np.mean((yhat[~boona]-y[~boona])**2))\n",
    "# print(f\"the rmse of simple interpolation is {rmse:.4f}\")\n",
    "# print(f\"shape of X {X.shape} --> shape of y=yhat {yhat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T05:20:23.914267Z",
     "start_time": "2022-09-05T05:20:23.890392Z"
    }
   },
   "outputs": [],
   "source": [
    "# #TODO: fix D and varkappa to reasonable values for the FK,LR models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Results__ \n",
    "\n",
    "#DONE: was the rmse high because I was using multiple slices with reflect=0 and 1? Yes.\n",
    "- linear nd interpolation was consistent to 1e-5 for fill_value=True versus False.\n",
    "- linear nd interpolation was consistent to 1e-16 for one output column at a time versus all 4 output columns\n",
    "- linear nd interpolation trained on D=0.2 data had an rmse_M = 0.0339837, which is much smaller than the unconstrained rmse_M = 0.7284194\n",
    "    - __Corollary__, if I have the brute force grid search already present, then it makes sense to use it in interpolation\n",
    " \n",
    "#DONE: confirmed slicing the dataframe fixed everything...\n",
    "- interpolating from d=4 to d=1 gave rmse_m=0.001 when constraining to periodic boundary conditions and the other procedural parameters to a single category of function, which was ~7X better than forgetting about that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T03:01:08.510172Z",
     "start_time": "2022-09-05T03:01:08.466138Z"
    }
   },
   "outputs": [],
   "source": [
    "# boo=df['D']==0.1\n",
    "#extract features X=(r,kappa,varkappa,D) to labels Y=(M,m) as cupy arrays\n",
    "X_col_lst=['r','kappa']\n",
    "# X_col_lst=['varkappa','D','r','kappa']\n",
    "# Y_col_lst=['M','m', 'Delta_M','Delta_m']\n",
    "Y_col_lst=['M','m', 'Delta_M','Delta_m', 'Rsq']\n",
    "# Y_col_lst=\"M\"#['M']#,'m', 'Delta_M','Delta_m']\n",
    "# Xall=dg.loc[boo,X_col_lst].values\n",
    "# Yall=dg.loc[boo,Y_col_lst].values\n",
    "Xall=dg[X_col_lst].values\n",
    "Yall=dg[Y_col_lst].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TODO: fix D and varkappa to reasonable values for the FK,LR models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.979848Z",
     "start_time": "2022-09-05T02:19:52.979838Z"
    }
   },
   "outputs": [],
   "source": [
    "#compute the linear interpolating function from (r,kappa,varkappa,D) to (M,m)\n",
    "#TODO: find a cupy implementation of LinearNDInterpolator\n",
    "X=Xall.get()\n",
    "Y=Yall.get()\n",
    "\n",
    "# xgrid = np.mgrid[-1:1:50j, -1:1:50j]\n",
    "# interp = scipy.interpolate.RBFInterpolator(X, Y, \n",
    "#                                            neighbors=15,\n",
    "# #                                            smoothing=1.,kernel='linear')#(xflat){'thin_plate_spline', 'cubic', 'quintic', 'linear'}.\n",
    "# #                                            smoothing=0.001,kernel='linear')#(xflat){'thin_plate_spline', 'cubic', 'quintic', 'linear'}.\n",
    "#                                            smoothing=0.001,kernel='gaussian',epsilon=0.1)#(xflat){'thin_plate_spline', 'cubic', 'quintic', 'linear'}.\n",
    "\n",
    "# # #DONE: test if the imperfect interpolation is the result of having multiple target values\n",
    "# interp=LinearNDInterpolator(points=X, values=Y, rescale=False)\n",
    "# # # interp=LinearNDInterpolator(points=X, values=Y)#, fill_value=np.nan, rescale=True)\n",
    "# # # interp=LinearNDInterpolator(points=X.get(), values=Y.get(), fill_value=np.nan, rescale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.980685Z",
     "start_time": "2022-09-05T02:19:52.980675Z"
    }
   },
   "outputs": [],
   "source": [
    "from lib.lib_care.routines.interp_texture_from_scatter_data import *\n",
    "from lib.lib_care.measure.level_sets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.982106Z",
     "start_time": "2022-09-05T02:19:52.982087Z"
    }
   },
   "outputs": [],
   "source": [
    "# from inspect import signature\n",
    "\n",
    "# signature(interp).parameters#, follow_wrapped=True)\n",
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.983524Z",
     "start_time": "2022-09-05T02:19:52.983503Z"
    }
   },
   "outputs": [],
   "source": [
    "# Yhat=interp(X)\n",
    "# print('the inputs can be evaluated!')\n",
    "\n",
    "# se=(cp.array(Yhat)-Yall)**2\n",
    "# boona=cp.isnan(se[:,0])\n",
    "# # Y[boona,0],cp.array(Yhat)[boona,0]  #was one row only when I looked\n",
    "# mse=cp.mean(se[~boona],axis=0)\n",
    "# rmse=cp.sqrt(mse)\n",
    "# # interp=LinearNDInterpolator(points=X.get(), values=Y.get())#, fill_value=np.nan, rescale=True)\n",
    "# print(f\"the rmse of linear interpolation is\\n\\t{rmse}\\nfor\\t{Y_col_lst}\")\n",
    "\n",
    "# # # # DONE: test rmse of the linear RBFInterpolator with 15 neighbors\n",
    "# # the inputs can be evaluated!\n",
    "# # the rmse of linear interpolation is\n",
    "# # \t[0.0933669  0.00072217 0.0453468  0.00012483]\n",
    "# # for\t['M', 'm', 'Delta_M', 'Delta_m']\n",
    "\n",
    "# # # DONE: test rmse of the linear RBFInterpolator with 300 neighbors\n",
    "# # the inputs can be evaluated!\n",
    "# # the rmse of linear interpolation is\n",
    "# # \t[0.08795691 0.00070626 0.04275492 0.00012456]\n",
    "# # for\t['M', 'm', 'Delta_M', 'Delta_m']\n",
    "\n",
    "# # # # DONE: test rmse of the linear RBFInterpolator with 3 neighbors\n",
    "# # the inputs can be evaluated!\n",
    "# # the rmse of linear interpolation is\n",
    "# # \t[1.47973001e-01 9.47869258e-04 6.10703994e-02 1.28425583e-04]\n",
    "# # for\t['M', 'm', 'Delta_M', 'Delta_m']\n",
    "\n",
    "# # DONE(if rmse is still too big here...): simply repeat with varkappa,D fixed\n",
    "# # the rmse of simple interpolation is 0.0010\n",
    "# # #for rescale=False,\n",
    "# # the rmse of linear interpolation is\n",
    "# # \t[0.11341626 0.00096018 0.05280392 0.00017267]\n",
    "# # for\t['M', 'm', 'Delta_M', 'Delta_m']\n",
    "\n",
    "# # #for rescale=True,\n",
    "# # the rmse of linear interpolation is\n",
    "# # \t[0.11341453 0.00096017 0.05280311 0.00017267]\n",
    "# # for\t['M', 'm', 'Delta_M', 'Delta_m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.985052Z",
     "start_time": "2022-09-05T02:19:52.985036Z"
    }
   },
   "outputs": [],
   "source": [
    "# X.shape,X_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.986276Z",
     "start_time": "2022-09-05T02:19:52.986262Z"
    }
   },
   "outputs": [],
   "source": [
    "# #make a uniform grid over two axes at r,kappa conditioned on varkappa,D\n",
    "# x1col=0\n",
    "# x2col=1\n",
    "# num_samples=100\n",
    "\n",
    "# xi=[]\n",
    "# x1=X[:,x1col]\n",
    "# xi.append(np.linspace(np.min(x1), np.max(x1),num_samples))\n",
    "# x2=X[:,x2col]\n",
    "# xi.append(np.linspace(np.min(x2), np.max(x2),num_samples))\n",
    "# XI=np.meshgrid(*xi)\n",
    "# # print(len(XI))\n",
    "# x1_values=XI[0]\n",
    "# x2_values=XI[1]\n",
    "\n",
    "# #holding varkappa and D fixed, interpolate from r,kappa to Yhat\n",
    "# # np.array(list(zip(XI))).shape\n",
    "# gridshape=x1_values.shape\n",
    "# X_values=np.array(list(zip((x1_values.flatten(),x2_values.flatten()))))[:,0,:].T#[:,fixed_row,:].T\n",
    "# print(X_values.shape)\n",
    "\n",
    "# #compute the interpolated values of y on this 2D grid for each \n",
    "# # interp = LinearNDInterpolator(X, y)\n",
    "# interp = CloughTocher2DInterpolator(X, Y)\n",
    "# Y_values = interp(X_values).reshape(gridshape[0],gridshape[1],len(Y_col_lst))\n",
    "# Y_values.shape,X_values.shape,x1_values.shape\n",
    "# # print(np.max(x1_values))\n",
    "\n",
    "# # return x1_values.shape,x2_values.shape,Y_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LinearNDFit is the problem for why I can't get contours__ The input m values include 1.6~1.8, while interpolated values apparently do not.\n",
    "\n",
    "TODO: interpolate using radial basis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.987874Z",
     "start_time": "2022-09-05T02:19:52.987858Z"
    }
   },
   "outputs": [],
   "source": [
    "y=Y[:,0]\n",
    "#interpolate textures from scatter plots\n",
    "x1_values,x2_values,y_values = interp_txt_from_scatter(X,y,nsamples=1000,mode ='spline')\n",
    "compute_powerlaw_levelsets\n",
    "\n",
    "model_name='fk_pbc'\n",
    "navg=50\n",
    "output_col='m'\n",
    "level=wjr[model_name][output_col]\n",
    "y=Y[...,1]\n",
    "contour_m_values=comp_longest_level_set_and_smooth(X,y,level,navg=navg)\n",
    "\n",
    "output_col='M'\n",
    "level=wjr[model_name][output_col]\n",
    "y=Y[...,0]\n",
    "contour_M_values=comp_longest_level_set_and_smooth(X,y,level,navg=navg)\n",
    "\n",
    "\n",
    "\n",
    "x1star_values, x2star_values=compute_intersections(contour_m_values,contour_M_values)\n",
    "x1star_values, x2star_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.989791Z",
     "start_time": "2022-09-05T02:19:52.989762Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.hist(Y_values[:,1].flatten(),density=True)\n",
    "# plt.hist(Y[:,1].flatten(),density=True)\n",
    "# print(f\"are we seeing smaller exponents 1.6~1.8?\")\n",
    "# print((Y[:,1].flatten().min(),Y[:,1].flatten().max()))\n",
    "# print((Y_values[:,1].flatten().min(),Y_values[:,1].flatten().max()))\n",
    "# plt.ylabel(r'$\\nu$')\n",
    "# plt.xlim([0,10])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.991648Z",
     "start_time": "2022-09-05T02:19:52.991618Z"
    }
   },
   "outputs": [],
   "source": [
    "from lib.lib_care.measure.level_sets import comp_longest_level_set_and_smooth\n",
    "#TODO: compute the level set contours\n",
    "def compute_powerlaw_levelsets(X,Y,model_name='fk_pbc',\n",
    "                              navg=50,m_col=1,M_col=0,\n",
    "                              **kwargs):\n",
    "#     num_points=x1_values.shape[0]*x1_values.shape[1]\n",
    "#     X_values=np.stack((x1_values,x2_values)).reshape((num_points,2))\n",
    "    output_col='m'\n",
    "    level=wjr[model_name][output_col]#;print(level)\n",
    "#     y=y_m#Y_values[...,m_col].flatten()\n",
    "    y=Y[...,m_col]\n",
    "    contour_m_values=comp_longest_level_set_and_smooth(X,y,level,navg=navg)\n",
    "\n",
    "    output_col='M'\n",
    "    level=wjr[model_name][output_col]#;print(level)\n",
    "    y=Y[...,M_col]\n",
    "#     y=y_M#Y_values[...,M_col].flatten()\n",
    "    contour_M_values=comp_longest_level_set_and_smooth(X,y,level,navg=navg)\n",
    "    return contour_m_values,contour_M_values\n",
    "\n",
    "\n",
    "# - TODO: find any a:=varkappa value that supports power law fits for both full models\n",
    "# - TODO: find an upper and lower bound on the a:=varkappa values that support power law fits for both full models\n",
    "try:\n",
    "    contour_m_values,contour_M_values = compute_powerlaw_levelsets(X,Y,model_name='fk_pbc')\n",
    "#                               navg=50,m_col=1,M_col=0)\n",
    "    print(f\"---: fenton-karma model might be supported\")\n",
    "except AssertionError as e:\n",
    "    print(f\"{e}: fenton-karma model not supported anywhere\")\n",
    "    \n",
    "try:\n",
    "    contour_m_values,contour_M_values = compute_powerlaw_levelsets(X,Y,model_name='lr_pbc')\n",
    "#                               navg=50,m_col=1,M_col=0)\n",
    "    print(f\"---: luo-rudy model might be supported\")\n",
    "except AssertionError as e:\n",
    "    print(f\"{e}: luo-rudy     model not supported anywhere\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.993050Z",
     "start_time": "2022-09-05T02:19:52.993036Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "contour_m_values,contour_M_values = compute_powerlaw_levelsets(X,Y,model_name='fk_pbc')\n",
    "x1star_values, x2star_values=compute_intersections(contour_m_values,contour_M_values)\n",
    "print((x1star_values.size))\n",
    "\n",
    "contour_m_values,contour_M_values = compute_powerlaw_levelsets(X,Y,model_name='lr_pbc')\n",
    "x1star_values, x2star_values=compute_intersections(contour_m_values,contour_M_values)\n",
    "print((x1star_values.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.994673Z",
     "start_time": "2022-09-05T02:19:52.994659Z"
    }
   },
   "outputs": [],
   "source": [
    "# #plot the interpolated m (left) and the interpolated M (right) for each pixel.\n",
    "# #visualize r versus kappa conditioned on varkappa and D\n",
    "# x1lim=[np.min(x1_values),np.max(x1_values)]\n",
    "# x2lim=[np.min(x2_values),np.max(x2_values)]\n",
    "# fontsize=18\n",
    "# xlabel=r'$r$ (cm)'\n",
    "# ylabel=r'$\\kappa$ (Hz)'\n",
    "# cmap = mpl.cm.cool\n",
    "\n",
    "# #columnal kwargs\n",
    "# vmin_lst=[1,0]\n",
    "# vmax_lst=[3,30]\n",
    "# output_col_lst=[1,0]#['m','M']\n",
    "# #kwargs by row\n",
    "# fig, axs = plt.subplots(ncols=2, figsize=(11,5))\n",
    "# cmaps = ['RdBu_r', 'viridis']\n",
    "# title_lst=[\n",
    "#     f'a={varkappa}'+r'cm$^2$/s'+f', D={D}'+r'cm$^2$/s'+f'\\n',\n",
    "#     ''#f'M={M}'+r'cm$^{2(\\nu-1)}$/s, $\\nu$'+f'={m}\\n'\n",
    "# ]\n",
    "# clabel_lst=[r'$\\nu$',r'M cm$^{2(\\nu-1)}$/s']\n",
    "# nsamples=1000\n",
    "# for col in range(len(output_col_lst)):\n",
    "#     output_col=output_col_lst[col]\n",
    "#     y=Y[output_col]\n",
    "#     x1_values,x2_values,y_values = interp_txt_from_scatter(X,y,nsamples=1000,mode ='spline')\n",
    "    \n",
    "#     contour_m_values_FK,contour_M_values_FK= compute_powerlaw_levelsets(X,Y,model_name='fk_pbc')\n",
    "#     contour_m_values_LR,contour_M_values_LR= compute_powerlaw_levelsets(X,Y,model_name='lr_pbc')\n",
    "    \n",
    "#     ax = axs[col]\n",
    "#     vmin=vmin_lst[col]\n",
    "#     vmax=vmax_lst[col]\n",
    "\n",
    "# #         vmin=np.quantile(y_values.flatten(),0.25)\n",
    "# #         vmax=np.quantile(y_values.flatten(),0.75)\n",
    "#     pcm=ax.pcolormesh(x1_values, x2_values, y_values, vmin=vmin, vmax=vmax, cmap=cmaps[col],shading='auto')\n",
    "\n",
    "\n",
    "    \n",
    "# #         ax.set_xlim(x1lim)\n",
    "# #         ax.set_ylim(x2lim)\n",
    "#     title=title_lst[col]\n",
    "#     ax.set_title(title,fontsize=fontsize)\n",
    "#     format_plot(ax, xlabel, ylabel, fontsize)#, use_loglog=False\n",
    "# #     print(np.max(x1_values))\n",
    "# #     fig.colorbar(pcm, ax=[axs[0, col]], location='top', shrink=0.6)\n",
    "#     cbar=fig.colorbar(pcm, ax=axs[col],shrink=0.6)#,label=output_col)\n",
    "#     cbar.ax.tick_params(labelsize=fontsize)\n",
    "#     cbar.set_label(clabel_lst[col], fontsize=fontsize)    \n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.996031Z",
     "start_time": "2022-09-05T02:19:52.996013Z"
    }
   },
   "outputs": [],
   "source": [
    "X.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.997959Z",
     "start_time": "2022-09-05T02:19:52.997945Z"
    }
   },
   "outputs": [],
   "source": [
    "D=0.3\n",
    "varkappa=15\n",
    "#visualize the level sets\n",
    "#compute the data for background image \n",
    "query = cp.isclose(df['D'],D)\n",
    "query&= (df['varkappa']==varkappa)\n",
    "query&= query_template\n",
    "\n",
    "#TODO: make plotting the background colored image functional\n",
    "#visualize a versus r\n",
    "x1lim=[0.05,0.5]\n",
    "x2lim=[100,1500]\n",
    "# x2lim=[0,50]\n",
    "fontsize=16\n",
    "x1label=r'$r$ (cm)'\n",
    "x2label=r'$\\kappa$ (cm$^2$/s)'\n",
    "\n",
    "title_foo=lambda varkappa,D:f'a = {varkappa:.1f} '+r'cm$^2$/s'+f', D = {D:.1f} '+r'cm$^2$/s'+f'\\n'\n",
    "title=title_foo(varkappa,D)\n",
    "lw=3\n",
    "alpha=0.7\n",
    "cmap = 'gray'#'bone'  #'RdBu_r'#'Greys'# \n",
    "use_cbar=True\n",
    "show_cbar =True\n",
    "use_loglog=False\n",
    "\n",
    "kwargs={}\n",
    "\n",
    "X=df.loc[query,['r','kappa']].values.get()\n",
    "Y=df.loc[query,['M','m']].values.get()\n",
    "contour_m_values_FK,contour_M_values_FK= compute_powerlaw_levelsets(X,Y,model_name='fk_pbc')\n",
    "contour_m_values_LR,contour_M_values_LR= compute_powerlaw_levelsets(X,Y,model_name='lr_pbc')\n",
    "\n",
    "figsize=(11,4.5)#(6,4.5)#(16,6)#(16,14)\n",
    "fig,axs=plt.subplots(ncols=2, figsize=figsize)\n",
    "\n",
    "#DONE: plot fig. A contours for m\n",
    "ax=axs[0]\n",
    "output_col='m'\n",
    "vmin=1\n",
    "vmax=3\n",
    "\n",
    "y=df.loc[query,output_col].values.get()\n",
    "x1_values,x2_values,y_values=interp_txt_from_scatter(X,y,nsamples=1000)\n",
    "# clabel=output_col\n",
    "clabel=r'$\\nu$'\n",
    "\n",
    "PlotInterpolatedBackground(fig,ax,x1_values,x2_values,y_values,vmin,vmax,clabel,cmap,fontsize=fontsize,show_cbar=show_cbar,**kwargs)\n",
    "FormatAxes(ax,x1lim=x1lim,x2lim=x2lim,x1label=x1label,x2label=x2label,title=title,fontsize=fontsize,use_loglog=use_loglog,**kwargs)      \n",
    "\n",
    "#DONE: plot the level sets and color them for the full models\n",
    "ax.plot(contour_m_values_FK[:,0],contour_m_values_FK[:,1],'-',lw=lw,alpha=alpha,c='C0',**kwargs)\n",
    "ax.plot(contour_m_values_LR[:,0],contour_m_values_LR[:,1],'-',lw=lw,alpha=alpha,c='C1',**kwargs)\n",
    "#DONE: plot the level sets and color them for the full models\n",
    "ax.plot(contour_M_values_FK[:,0],contour_M_values_FK[:,1],'--',lw=lw,alpha=alpha,c='C0',**kwargs)\n",
    "ax.plot(contour_M_values_LR[:,0],contour_M_values_LR[:,1],'--',lw=lw,alpha=alpha,c='C1',**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "#DONE: plot fig. B contours for M\n",
    "ax=axs[1]\n",
    "output_col='M'\n",
    "vmin=0\n",
    "vmax=30\n",
    "y=df.loc[query,output_col].values.get()\n",
    "x1_values,x2_values,y_values=interp_txt_from_scatter(X,y,nsamples=1000)\n",
    "clabel=output_col\n",
    "\n",
    "x1star_values, x2star_values=compute_intersections(contour_m_values_FK,contour_M_values_FK)\n",
    "num_intersections_FK=x1star_values.size\n",
    "\n",
    "x1star_values, x2star_values=compute_intersections(contour_m_values_LR,contour_M_values_LR)\n",
    "num_intersections_LR=x1star_values.size\n",
    "title2=f\"num. crosses:\\n{num_intersections_FK} (FK) and {num_intersections_LR} (LR)\\n\"\n",
    "\n",
    "PlotInterpolatedBackground(fig,ax,x1_values,x2_values,y_values,vmin,vmax,clabel,cmap,fontsize=fontsize,show_cbar=show_cbar,**kwargs)\n",
    "FormatAxes(ax,x1lim=x1lim,x2lim=x2lim,x1label=x1label,x2label=x2label,title=title2,fontsize=fontsize,use_loglog=use_loglog,**kwargs)      \n",
    "\n",
    "#DONE: plot the level sets and color them for the full models\n",
    "ax.plot(contour_m_values_FK[:,0],contour_m_values_FK[:,1],'-',lw=lw,alpha=alpha,c='C0',**kwargs)\n",
    "ax.plot(contour_m_values_LR[:,0],contour_m_values_LR[:,1],'-',lw=lw,alpha=alpha,c='C1',**kwargs)\n",
    "\n",
    "#DONE: plot the level sets and color them for the full models\n",
    "ax.plot(contour_M_values_FK[:,0],contour_M_values_FK[:,1],'--',lw=lw,alpha=alpha,c='C0',**kwargs)\n",
    "ax.plot(contour_M_values_LR[:,0],contour_M_values_LR[:,1],'--',lw=lw,alpha=alpha,c='C1',**kwargs)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:19:52.999037Z",
     "start_time": "2022-09-05T02:19:52.999021Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: iterate over all a,D values and print the number of self-consistent points found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
